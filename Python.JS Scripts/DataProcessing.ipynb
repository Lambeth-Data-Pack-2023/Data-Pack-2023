{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5b18cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1108,
   "id": "29d2d06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def converttojson(df, dfname):# Convert DataFrame to JSON\n",
    "    json_data = df.to_json(orient='records')\n",
    "    file_path = f\"Clean Data/{dfname}.json\"\n",
    "\n",
    "    # Optionally, save to a file if needed\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(json_data)\n",
    "    \n",
    "    print(f\"DataFrame '{dfname}' saved as JSON file: {file_path}\")\n",
    "\n",
    "def firstrowtocolname(df):\n",
    "    column_names = df.iloc[0]\n",
    "    # Remove the first row from the DataFrame\n",
    "    df = df[1:]\n",
    "    # Set the extracted row as column names\n",
    "    df.columns = column_names\n",
    "    # Reset the index after removing the first row\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "def fingertipsclean(df):\n",
    "    df= df[['AreaName','Time period', 'Value']]\n",
    "    df['AreaName'] = df['AreaName'].replace('London region', 'London')\n",
    "    df_filtered = df[-6:] #take the last six rows (2 years of data)\n",
    "    return df_filtered\n",
    "\n",
    "def censusclean(df):\n",
    "    new_columns=[df.columns[0]]\n",
    "    for i, col in enumerate(df.columns):\n",
    "        if pd.isna(col):\n",
    "            new_col_name = f\"{df.columns[i-1]} (%)\"\n",
    "            new_columns.append(new_col_name)\n",
    "        elif i != 0:\n",
    "            new_col_name = f\"{df.columns[i]} (number)\"\n",
    "            new_columns.append(new_col_name)\n",
    "    df.columns = new_columns\n",
    "    df = df.iloc[1:]\n",
    "    return df\n",
    "def crimerate(rawdf, offencegroup='', subgroup=''):\n",
    "    rawdf = rawdf.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    df = rawdf[rawdf['Area name'].isin(wards+['Lambeth']) & \n",
    "            (rawdf['Measure']=='Offences')]\n",
    "    if offencegroup != '':\n",
    "        df = df[(df['Offence Group'] == offencegroup)]\n",
    "    if subgroup != '':\n",
    "        df= df[df['Offence Subgroup'] == subgroup]\n",
    "    \n",
    "    df = df.iloc[:,[0,3,10]]\n",
    "    column_mapping = {df.columns[0]: 'Time period', df.columns[1]: 'AreaName'}\n",
    "    df = df.rename(columns=column_mapping)\n",
    "    df['Count'] = pd.to_numeric(df['Count'], errors='coerce')\n",
    "    df = df.groupby(['Time period','AreaName'], as_index=False).sum()\n",
    "\n",
    "    londondf = rawdf[(rawdf['Area Type']=='Borough') & (~rawdf['Area name'].str.contains('Aviation')) & \n",
    "            (rawdf['Measure']=='Offences')]\n",
    "    if offencegroup != '':\n",
    "        londondf = londondf[(londondf['Offence Group'] == offencegroup)]\n",
    "    if subgroup!= '':\n",
    "        londondf=londondf[londondf['Offence Subgroup'] == subgroup]\n",
    "    londondf = londondf.iloc[:,[0,3,10]]\n",
    "    column_mapping = {londondf.columns[0]: 'Time period', londondf.columns[1]: 'AreaName'}\n",
    "    londondf = londondf.rename(columns=column_mapping)\n",
    "    londondf['Count'] = pd.to_numeric(londondf['Count'], errors='coerce')\n",
    "    londondf = londondf.groupby(['Time period'], as_index=False).sum()\n",
    "    londondf['AreaName'] = 'London'\n",
    "    combineddf = pd.concat([df, londondf], ignore_index=True)\n",
    "    combineddf = pd.merge(pop, combineddf, on='AreaName', how='inner')\n",
    "    combineddf['Time period'] = combineddf['Time period'].str.replace(r'-01$', '', regex=True)    \n",
    "    combineddf['Population'] = pd.to_numeric(combineddf['Population'], errors='coerce')\n",
    "    combineddf['Offences per 1,000 people'] = (combineddf['Count']/combineddf['Population'] * 1000).round(1)\n",
    "    combineddf=combineddf.drop(columns=['Female','Male'])\n",
    "    return combineddf\n",
    "\n",
    "def create_surv_q_df(df, start_text=\"test col x vs y and z\", end_text_select=1):\n",
    "    surv_sat = df.iloc[:, :37]\n",
    "    indices_to_drop = list(range(3, 12))\n",
    "    surv_sat = surv_sat.drop(surv_sat.columns[indices_to_drop], axis=1)\n",
    "    question = str(surv_sat.iloc[0,0])\n",
    "\n",
    "    names = surv_sat.iloc[3, 2:].values\n",
    "    # Create boolean masks with no NaN values\n",
    "    start_mask = surv_sat.iloc[:,0].str.contains(start_text, regex=False, na=False)\n",
    "    end_mask = surv_sat.iloc[:,0].str.contains(\"Don’t know|Prefer not to say|NET\", regex=True, na=False)\n",
    "\n",
    "    # Find start and end indices for filtering\n",
    "    if not start_mask.any() or not end_mask.any():\n",
    "        raise ValueError(\"Start or end text not found in 'Response' column.\")\n",
    "\n",
    "    start_index = surv_sat[start_mask].index[0] + 1\n",
    "    end_indices = surv_sat[end_mask].index\n",
    "    if len(end_indices) < end_text_select:\n",
    "        raise ValueError(\"Insufficient matches for end text to use the specified end_text_select value.\")\n",
    "    end_index = end_indices[end_text_select - 1] - 1\n",
    "\n",
    "    surv_sat_f = surv_sat.loc[start_index:end_index]\n",
    "\n",
    "    columns=['Response','Percentage of respondents']\n",
    "    columns.extend(names)\n",
    "\n",
    "    # Rename the rest of the columns to 'Percentage of respondents'\n",
    "    column_mapping = {old_name: new_name for old_name, new_name in zip(surv_sat_f.columns, columns)}\n",
    "    surv_sat_f = surv_sat_f.rename(columns=column_mapping)\n",
    "    surv_sat_f = surv_sat_f.dropna(subset=[surv_sat_f.columns[0]])\n",
    "\n",
    "    # Replace numbers in square brackets in the 'Response' column\n",
    "    surv_sat_f['Response'] = surv_sat_f['Response'].str.replace(r\"\\[\\d+\\] \", \"\", regex=True)\n",
    "\n",
    "    # Convert 'Percentage of respondents' to numeric and handle any non-numeric gracefully\n",
    "    surv_sat_f.iloc[:, 1:] = surv_sat_f.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Multiply 'Percentage of respondents' by 100 to get percentage and round to 1 decimal place\n",
    "    surv_sat_f.iloc[:, 1:] = surv_sat_f.iloc[:, 1:] * 100\n",
    "    surv_sat_f.iloc[:, 1:] = surv_sat_f.iloc[:, 1:].round(1)\n",
    "\n",
    "    # Make column 'Question' with values from the question variable\n",
    "    surv_sat_f['Question'] = question\n",
    "\n",
    "    # Various string replacements and clean-ups on 'Question'\n",
    "    surv_sat_f['Question'] = surv_sat_f['Question'].str.replace(\"Q:\", \"\")\n",
    "    surv_sat_f['Question'] = surv_sat_f['Question'].str.replace(r\"^Q[A-Za-z0-9]+\", \"\", regex=True)\n",
    "    surv_sat_f['Question'] = surv_sat_f['Question'].str.replace(r\"^_[A-Za-z0-9]+\", \"\", regex=True)\n",
    "    surv_sat_f['Question'] = surv_sat_f['Question'].str.replace(r\"\\.\", \" \")\n",
    "    surv_sat_f['Question'] = surv_sat_f['Question'].str.strip()\n",
    "    return surv_sat_f\n",
    "\n",
    "def create_surv_q_df2022(df, start_text=\"test col x vs y and z\", end_text_select=1):\n",
    "    surv_sat = df.iloc[:, :2]\n",
    "\n",
    "    question = str(surv_sat.iloc[0,0])\n",
    "\n",
    "    # Create boolean masks with no NaN values\n",
    "    start_mask = surv_sat.iloc[:,0].str.contains(start_text, regex=False, na=False)\n",
    "    end_mask = surv_sat.iloc[:,0].str.contains(\"Don’t know|Prefer not to say|NET\", regex=True, na=False)\n",
    "\n",
    "    # Find start and end indices for filtering\n",
    "    if not start_mask.any() or not end_mask.any():\n",
    "        raise ValueError(\"Start or end text not found in 'Response' column.\")\n",
    "\n",
    "    start_index = surv_sat[start_mask].index[0] + 1\n",
    "    end_indices = surv_sat[end_mask].index\n",
    "    if len(end_indices) < end_text_select:\n",
    "        raise ValueError(\"Insufficient matches for end text to use the specified end_text_select value.\")\n",
    "    end_index = end_indices[end_text_select - 1] - 1\n",
    "\n",
    "    surv_sat_f = surv_sat.loc[start_index:end_index]\n",
    "\n",
    "    columns=['Response','Percentage of respondents']\n",
    "\n",
    "    # Rename the rest of the columns to 'Percentage of respondents'\n",
    "    column_mapping = {old_name: new_name for old_name, new_name in zip(surv_sat_f.columns, columns)}\n",
    "    surv_sat_f = surv_sat_f.rename(columns=column_mapping)\n",
    "    surv_sat_f = surv_sat_f.dropna(subset=[surv_sat_f.columns[0]])\n",
    "\n",
    "    # Replace numbers in square brackets in the 'Response' column\n",
    "    surv_sat_f['Response'] = surv_sat_f['Response'].str.replace(r\"\\[\\d+\\] \", \"\", regex=True)\n",
    "\n",
    "    \n",
    "    # Convert 'Percentage of respondents' to numeric and handle any non-numeric gracefully\n",
    "    surv_sat_f.iloc[:, 1:] = surv_sat_f.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Multiply 'Percentage of respondents' by 100 to get percentage and round to 1 decimal place\n",
    "    surv_sat_f.iloc[:, 1] = surv_sat_f.iloc[:, 1] * 100\n",
    "    surv_sat_f.iloc[:, 1] = surv_sat_f.iloc[:, 1].round(1)\n",
    "\n",
    "    # Make column 'Question' with values from the question variable\n",
    "    surv_sat_f['Question'] = question\n",
    "\n",
    "    # Various string replacements and clean-ups on 'Question'\n",
    "    surv_sat_f['Question'] = surv_sat_f['Question'].str.replace(\"Q:\", \"\")\n",
    "    surv_sat_f['Question'] = surv_sat_f['Question'].str.replace(r\"^Q[A-Za-z0-9]+\", \"\", regex=True)\n",
    "    surv_sat_f['Question'] = surv_sat_f['Question'].str.replace(r\"^_[A-Za-z0-9]+\", \"\", regex=True)\n",
    "    surv_sat_f['Question'] = surv_sat_f['Question'].str.replace(r\"\\.\", \" \")\n",
    "    surv_sat_f['Question'] = surv_sat_f['Question'].str.strip()\n",
    "    return surv_sat_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "id": "c9c5daf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Excel file containing file names of datasets\n",
    "data_sources = pd.read_excel('Data sources ambitions.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "4c9e49e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wards = [\"Brixton Acre Lane\",\"Brixton North\",\"Brixton Rush Common\",\"Brixton Windrush\",\n",
    "         \"Clapham Common & Abbeville\",\"Clapham East\",\"Clapham Park\",\"Clapham Town\",\"Gipsy Hill\",\n",
    "         \"Herne Hill & Loughborough Junction\",\"Kennington\",\"Knight's Hill\",\"Myatt's Fields\",\"Oval\",\n",
    "         \"St Martin's\",\"Stockwell East\",\"Stockwell West & Larkhall\",\"Streatham Common & Vale\",\n",
    "         \"Streatham Hill East\",\"Streatham Hill West & Thornton\",\"Streatham St Leonard's\",\n",
    "         \"Streatham Wells\",\"Vauxhall\",\"Waterloo & South Bank\",\"West Dulwich\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3de634",
   "metadata": {},
   "source": [
    "## Import current data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1181,
   "id": "d947c1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\Data\\Ambition 1\\Health and Wellbeing\\2023 ARS crosstabs.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:109: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  surv_sat_f.iloc[:, 1:] = surv_sat_f.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:122: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  surv_sat_f['Question'] = surv_sat_f['Question'].str.replace(r\"\\.\", \" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\Data\\Ambition 1\\Environment\\GreenHouseGasEmissions.csv\n",
      "CSV file successfully read with encoding: utf-8\n",
      "..\\Data\\Ambition 1\\Environment\\Recycling.ods\n",
      "..\\Data\\Ambition 1\\Environment\\EPCRatings.ods\n",
      "..\\Data\\Ambition 1\\Environment\\EPCRatings.ods\n",
      "..\\Data\\Ambition 1\\Environment\\EPCRatings.ods\n",
      "..\\Data\\Ambition 1\\Environment\\SolarPanelInstallations.xlsx\n",
      "..\\Data\\Ambition 1\\Environment\\osprivateoutdoorspacereferencetables.xlsx\n",
      "..\\Data\\Ambition 1\\Environment\\osprivateoutdoorspacereferencetables.xlsx\n",
      "..\\Data\\Ambition 1\\Environment\\osprivateoutdoorspacereferencetables.xlsx\n",
      "..\\Data\\Ambition 1\\Environment\\TreeCanopyCover.csv\n",
      "CSV file successfully read with encoding: utf-8\n",
      "..\\Data\\Ambition 2\\Crime, Safety & Justice\\MPS_MonthlyCrimeDashboard_TNOCrimeData23-24.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\3201268869.py:27: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dataframes[variable_name] = pd.read_csv(file_path, header=None, skiprows=skip, encoding = encoding)\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\3201268869.py:27: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dataframes[variable_name] = pd.read_csv(file_path, header=None, skiprows=skip, encoding = encoding)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file successfully read with encoding: utf-8\n",
      "..\\Data\\Ambition 2\\Crime, Safety & Justice\\MPS_MonthlyCrimeDashboard_OtherCrimeData23-24.csv\n",
      "CSV file successfully read with encoding: utf-8\n",
      "..\\Data\\Ambition 2\\Crime, Safety & Justice\\MPS_MonthlyCrimeDashboard_OtherCrimeData23-24.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\3201268869.py:27: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dataframes[variable_name] = pd.read_csv(file_path, header=None, skiprows=skip, encoding = encoding)\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\3201268869.py:27: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dataframes[variable_name] = pd.read_csv(file_path, header=None, skiprows=skip, encoding = encoding)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file successfully read with encoding: utf-8\n",
      "..\\Data\\Ambition 2\\Crime, Safety & Justice\\MPS_MonthlyCrimeDashboard_OtherCrimeData23-24.csv\n",
      "CSV file successfully read with encoding: utf-8\n",
      "..\\Data\\Ambition 2\\Crime, Safety & Justice\\MPS_MonthlyCrimeDashboard_OtherCrimeData23-24.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\3201268869.py:27: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dataframes[variable_name] = pd.read_csv(file_path, header=None, skiprows=skip, encoding = encoding)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file successfully read with encoding: utf-8\n",
      "..\\Data\\Ambition 2\\Crime, Safety & Justice\\MPS_MonthlyCrimeDashboard_TNOCrimeData23-24.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\3201268869.py:27: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dataframes[variable_name] = pd.read_csv(file_path, header=None, skiprows=skip, encoding = encoding)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file successfully read with encoding: utf-8\n",
      "..\\Data\\Ambition 2\\Crime, Safety & Justice\\ASB LDS.csv\n",
      "CSV file successfully read with encoding: utf-8\n",
      "..\\Data\\Ambition 2\\Crime, Safety & Justice\\ReoffendingRates.xlsx\n",
      "..\\Data\\Ambition 2\\Crime, Safety & Justice\\StopAndSearch.csv\n",
      "Failed to read CSV file with encoding: utf-8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\3201268869.py:27: DtypeWarning: Columns (10,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dataframes[variable_name] = pd.read_csv(file_path, header=None, skiprows=skip, encoding = encoding)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file successfully read with encoding: latin1\n",
      "..\\Data\\Ambition 2\\Crime, Safety & Justice\\PublicPerceptions.csv\n",
      "CSV file successfully read with encoding: utf-8\n",
      "..\\Data\\Ambition 2\\Crime, Safety & Justice\\2023 ARS crosstabs.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:109: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  surv_sat_f.iloc[:, 1:] = surv_sat_f.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:122: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  surv_sat_f['Question'] = surv_sat_f['Question'].str.replace(r\"\\.\", \" \")\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:109: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  surv_sat_f.iloc[:, 1:] = surv_sat_f.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:122: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  surv_sat_f['Question'] = surv_sat_f['Question'].str.replace(r\"\\.\", \" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\Data\\Ambition 2\\Crime, Safety & Justice\\2023 ARS crosstabs.xlsx\n",
      "..\\Data\\Ambition 2\\Crime, Safety & Justice\\2023 ARS crosstabs.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:109: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  surv_sat_f.iloc[:, 1:] = surv_sat_f.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:122: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  surv_sat_f['Question'] = surv_sat_f['Question'].str.replace(r\"\\.\", \" \")\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:109: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  surv_sat_f.iloc[:, 1:] = surv_sat_f.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:122: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  surv_sat_f['Question'] = surv_sat_f['Question'].str.replace(r\"\\.\", \" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\Data\\Ambition 2\\Crime, Safety & Justice\\2023 ARS crosstabs.xlsx\n",
      "..\\Data\\Ambition 2\\Crime, Safety & Justice\\TrafficIncidents.csv\n",
      "CSV file successfully read with encoding: utf-8\n",
      "..\\Data\\Ambition 3\\Jobs, earnings, and businesses\\Pop simple 16-64 2021.xlsx\n",
      "..\\Data\\Ambition 3\\Jobs, earnings, and businesses\\local units type 2023 NOMIS.xlsx\n",
      "..\\Data\\Ambition 3\\Jobs, earnings, and businesses\\Qualifications NOMIS 2023.xlsx\n",
      "..\\Data\\Ambition 3\\Jobs, earnings, and businesses\\PROV - Work Geography LWF Table 7 LWF.1a   lwfmgx 2023.xls\n",
      "..\\Data\\Ambition 3\\Jobs, earnings, and businesses\\Unemployment 16+ Sex and Ethnicity.xlsx\n",
      "..\\Data\\Ambition 3\\Jobs, earnings, and businesses\\Claimant Count.xlsx\n",
      "..\\Data\\Ambition 3\\Jobs, earnings, and businesses\\Business Birth and Closure Rate 2022.xlsx\n",
      "..\\Data\\Ambition 3\\Jobs, earnings, and businesses\\Business Birth and Closure Rate 2022.xlsx\n",
      "..\\Data\\Ambition 3\\Jobs, earnings, and businesses\\nndr Quarterly 2019-2023.csv\n",
      "CSV file successfully read with encoding: utf-8\n",
      "..\\Data\\Ambition 3\\Education\\2_early_years_provision_provider_type_2023.csv\n",
      "CSV file successfully read with encoding: utf-8\n",
      "..\\Data\\Ambition 3\\Education\\5_early_years_provision_ofsted_2023_corrected.csv\n",
      "CSV file successfully read with encoding: utf-8\n",
      "..\\Data\\Ambition 3\\Education\\2_eyfsp_early_learning_goals_areas_of_learning_2022_2023.csv\n",
      "CSV file successfully read with encoding: utf-8\n",
      "..\\Data\\Ambition 3\\Education\\ks2_regional_and_local_authority_2023_revised.csv\n",
      "CSV file successfully read with encoding: utf-8\n",
      "..\\Data\\Ambition 3\\Education\\2223_la_data_revised.csv\n",
      "CSV file successfully read with encoding: utf-8\n",
      "..\\Data\\Ambition 3\\Education\\2223_la_char_data_revised.csv\n",
      "CSV file successfully read with encoding: utf-8\n",
      "..\\Data\\Ambition 3\\Education\\2223_sl_lad_fsm_dis_data_revised.csv\n",
      "CSV file successfully read with encoding: utf-8\n",
      "..\\Data\\Ambition 3\\Education\\data-16-18-destination-measures-merged.csv\n",
      "CSV file successfully read with encoding: utf-8\n",
      "..\\Data\\Ambition 3\\Education\\data-participation-in-education-training-and-neet-age-16-to-17-by-local-authority.csv\n",
      "CSV file successfully read with encoding: utf-8\n",
      "..\\Data\\Ambition 3\\Education\\data-la-and-school-expenditure.csv\n",
      "CSV file successfully read with encoding: utf-8\n",
      "..\\Data\\Ambition 3\\Housing and infrastructure\\LT_100.ods\n",
      "..\\Data\\Ambition 3\\Housing and infrastructure\\hpssadataset9medianpricepaidforadministrativegeographies.xls\n",
      "..\\Data\\Ambition 3\\Housing and infrastructure\\hpssadataset9medianpricepaidforadministrativegeographies.xls\n",
      "..\\Data\\Ambition 3\\Housing and infrastructure\\CTSOP1.0_SUPP.xlsx\n",
      "..\\Data\\Ambition 3\\Housing and infrastructure\\Borough AvPTAI2015.csv\n",
      "CSV file successfully read with encoding: utf-8\n",
      "..\\Data\\Ambition 3\\Housing and infrastructure\\local_authority_traffic.csv\n",
      "CSV file successfully read with encoding: utf-8\n",
      "..\\Data\\Ambition 3\\Community\\2023 ARS crosstabs.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:109: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  surv_sat_f.iloc[:, 1:] = surv_sat_f.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:122: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  surv_sat_f['Question'] = surv_sat_f['Question'].str.replace(r\"\\.\", \" \")\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:109: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  surv_sat_f.iloc[:, 1:] = surv_sat_f.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:122: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  surv_sat_f['Question'] = surv_sat_f['Question'].str.replace(r\"\\.\", \" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\Data\\Ambition 3\\Community\\2023 ARS crosstabs.xlsx\n",
      "..\\Data\\Ambition 3\\Community\\2023 ARS crosstabs.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:109: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  surv_sat_f.iloc[:, 1:] = surv_sat_f.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:122: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  surv_sat_f['Question'] = surv_sat_f['Question'].str.replace(r\"\\.\", \" \")\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:109: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  surv_sat_f.iloc[:, 1:] = surv_sat_f.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:122: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  surv_sat_f['Question'] = surv_sat_f['Question'].str.replace(r\"\\.\", \" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\Data\\Ambition 3\\Community\\2023 ARS crosstabs.xlsx\n",
      "..\\Data\\Ambition 3\\Community\\2023 ARS crosstabs.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:109: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  surv_sat_f.iloc[:, 1:] = surv_sat_f.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:122: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  surv_sat_f['Question'] = surv_sat_f['Question'].str.replace(r\"\\.\", \" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\Data\\Ambition 3\\Community\\2023 ARS crosstabs.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:109: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  surv_sat_f.iloc[:, 1:] = surv_sat_f.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:122: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  surv_sat_f['Question'] = surv_sat_f['Question'].str.replace(r\"\\.\", \" \")\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:109: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  surv_sat_f.iloc[:, 1:] = surv_sat_f.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:122: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  surv_sat_f['Question'] = surv_sat_f['Question'].str.replace(r\"\\.\", \" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\Data\\Ambition 3\\Community\\2023 ARS crosstabs.xlsx\n",
      "..\\Data\\Ambition 3\\Community\\2023 ARS crosstabs.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:109: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  surv_sat_f.iloc[:, 1:] = surv_sat_f.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:122: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  surv_sat_f['Question'] = surv_sat_f['Question'].str.replace(r\"\\.\", \" \")\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:109: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  surv_sat_f.iloc[:, 1:] = surv_sat_f.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\Data\\Golden Thread\\2023 ARS crosstabs.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:122: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  surv_sat_f['Question'] = surv_sat_f['Question'].str.replace(r\"\\.\", \" \")\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:109: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  surv_sat_f.iloc[:, 1:] = surv_sat_f.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:122: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  surv_sat_f['Question'] = surv_sat_f['Question'].str.replace(r\"\\.\", \" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\Data\\Golden Thread\\2023 ARS crosstabs.xlsx\n",
      "..\\Data\\Golden Thread\\2023 ARS crosstabs.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:109: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  surv_sat_f.iloc[:, 1:] = surv_sat_f.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:122: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  surv_sat_f['Question'] = surv_sat_f['Question'].str.replace(r\"\\.\", \" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\Data\\Golden Thread\\CBP7096-trends-by-country-and-region.xlsx\n",
      "..\\Data\\Golden Thread\\Poverty rates by London borough (2021_22).csv\n",
      "CSV file successfully read with encoding: utf-8\n",
      "..\\Data\\Golden Thread\\children-in-low-income-families-local-area-statistics-2014-to-2023.ods\n",
      "..\\Data\\Golden Thread\\Child-Poverty-AHC-estimates-2015-2022_final.xlsx\n",
      "..\\Data\\Golden Thread\\Child-Poverty-AHC-estimates-2015-2022_final.xlsx\n",
      "..\\Data\\Golden Thread\\Pension Credit.xlsx\n",
      "..\\Data\\Golden Thread\\electoralstatstables2023v2.xlsx\n",
      "..\\Data\\Golden Thread\\2022 England Electoral Turnout data.xlsx\n",
      "..\\Data\\Golden Thread\\2022 England Electoral Turnout data.xlsx\n"
     ]
    }
   ],
   "source": [
    "dataframes = {}\n",
    "# Iterate over the rows to get the file paths\n",
    "for index, row in data_sources.iterrows():\n",
    "    if row['exported?'] == 'y': # comment out when re-importing everything\n",
    "        continue\n",
    "    if pd.isna(row['File Name']):\n",
    "        continue\n",
    "    if row['Ambition'] == 'Golden Thread':\n",
    "        ambition_folder = '..\\Data\\Golden Thread\\\\'\n",
    "    else:\n",
    "        ambition_folder = '..\\Data\\Ambition '+ str(row['Ambition']) + '\\\\' + str(row['Section'])\n",
    "    \n",
    "    file_name = str(row['File Name'])\n",
    "    variable_name = row['Internal link suffix']\n",
    "    sheet_name = str(row['Sheet']) if 'Sheet' in row and pd.notna(row['Sheet']) else 0\n",
    "    skip = int(row['Skip rows']) if 'Skip rows' in row and pd.notna(row['Skip rows']) else None\n",
    "    numrows = int(row['nrows']) if 'nrows' in row and pd.notna(row['nrows']) else None\n",
    "    file_path = os.path.join(ambition_folder, file_name)\n",
    "    print(file_path)\n",
    "\n",
    "    # Load the data (example for CSV)\n",
    "    if file_path.endswith('.csv'):\n",
    "        # Try reading the CSV file with different encodings\n",
    "        encodings_to_try = ['utf-8', 'latin1', 'ISO-8859-1', 'cp1252', 'utf-16']\n",
    "        for encoding in encodings_to_try:\n",
    "            try:\n",
    "                dataframes[variable_name] = pd.read_csv(file_path, header=None, skiprows=skip, encoding = encoding)\n",
    "                print(f\"CSV file successfully read with encoding: {encoding}\")\n",
    "                break  # Stop trying encodings if successful\n",
    "            except UnicodeDecodeError:\n",
    "                print(f\"Failed to read CSV file with encoding: {encoding}\") \n",
    "        \n",
    "        # Perform operations on the data\n",
    "    elif file_path.endswith('.xlsx') or file_path.endswith('.xls'):\n",
    "        dataframes[variable_name] = pd.read_excel(file_path, sheet_name = sheet_name, header=None, \n",
    "                                                  skiprows=skip, nrows=numrows)\n",
    "    elif file_path.endswith('.ods'):\n",
    "        dataframes[variable_name] = pd.read_excel(file_path, engine = 'odf', sheet_name = sheet_name, header=None, skiprows=skip)\n",
    "        # Perform operations on the data\n",
    "    if row['File Name'] == '2023 ARS crosstabs.xlsx':\n",
    "        dataframes[variable_name] = create_surv_q_df(dataframes[variable_name])\n",
    "    elif 'OtherCrime' in row['File Name']:\n",
    "        dataframes[variable_name] = firstrowtocolname(dataframes[variable_name])\n",
    "        column_mapping = {'Crime Type': 'Offence Group', 'Crime Subtype':'Offence Subgroup', 'Area Name' : 'Area name'}\n",
    "        dataframes[variable_name] = dataframes[variable_name].rename(columns=column_mapping)\n",
    "        \n",
    "    else:\n",
    "        dataframes[variable_name] = firstrowtocolname(dataframes[variable_name])\n",
    "\n",
    "# uncomment when running everything again\n",
    "    if row['Source organisation'] == 'Fingertips':\n",
    "        dataframes[variable_name]= fingertipsclean(dataframes[variable_name])\n",
    "        converttojson(dataframes[variable_name], variable_name)\n",
    "    elif row['Source organisation'] == 'ONS':\n",
    "        dataframes[variable_name] = dataframes[variable_name][:-3] #remove last three rows\n",
    "        dataframes[variable_name] = dataframes[variable_name].dropna(how='all')\n",
    "    elif row['Source organisation'] == 'ONS Census':\n",
    "        # Remove anything before \":\" in row names\n",
    "        dataframes[variable_name].iloc[:,0] = dataframes[variable_name].iloc[:,0].str.split(':').str[-1]\n",
    "        dataframes[variable_name] = dataframes[variable_name][:-2] #remove last two rows\n",
    "        dataframes[variable_name] = dataframes[variable_name].dropna(how='all')\n",
    "        dataframes[variable_name].columns = dataframes[variable_name].columns.str.replace(r'^.*:', '')\n",
    "        dataframes[variable_name].columns = dataframes[variable_name].columns.str.replace(r'\\s*\\(Lambeth\\)', '', regex=True)\n",
    "        dataframes[variable_name] = dataframes[variable_name].rename(columns={'Area': 'AreaName'})\n",
    "        if 'AreaName' in dataframes[variable_name].columns:\n",
    "            dataframes[variable_name]['AreaName'] = dataframes[variable_name]['AreaName'].str.replace(r'\\s*\\(Lambeth\\)', '', regex=True)\n",
    "        if dataframes[variable_name].iloc[0].str.contains('number').any():\n",
    "            dataframes[variable_name]= censusclean(dataframes[variable_name])\n",
    "        converttojson(dataframes[variable_name], variable_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "id": "cc910d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = dataframes['population-by-sex']\n",
    "pop['Population'] = pop['Female'] +pop['Male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1028,
   "id": "d30c1903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['childhood-vaccinations', 'healthy-weight---reception', 'healthy-weight---year-6', 'good-level-of-development---age-5', 'wellbeing---resident-survey-worthwhile', 'wellbeing---resident-survey-anxiety', 'personal-wellbeing', 'sexual-health', 'physical-exercise', 'healthy-weight', 'smoking', 'high-blood-pressure', 'drug-and-alcohol-misuse', 'diabetes', 'depression', 'coronary-heart-disease', 'male-life-expectancy-at-birth', 'female-life-expectancy-at-birth', 'male-healthy-life-expectancy', 'female-healthy-life-expectancy', 'deaths-under-75-from-preventable-causes', 'preventable-mortality---cancer', 'preventable-mortality---cardiovascular-disease', 'preventable-mortality---liver-disease', 'preventable-mortality---respiratory-disease', 'greenhouse-gas-emissions', 'recycling-rates', 'energy-performance-certificate-ratings-Lambeth', 'energy-performance-certificate-ratings-London', 'energy-performance-certificate-ratings-England', 'solar-panel-installations', 'access-to-public-green-space-england', 'access-to-public-green-space-london', 'access-to-public-green-space-lambeth', 'tree-canopy-cover', 'method-of-travel-to-work', 'overall-crime-rate', 'violent-crime-rate', 'knife-crime-rate', 'knife-crime-rate-with-victims-younger-than-25', 'domestic-abuse-crime-rate', 'hate-crime-rate', 'drug-related-crime-rate', 'domestic-burglary-crime-rate', 'anti-social-behaviour', 'reoffending-rates', 'stop-and-search', 'public-perception-of-police', 'resident-survey-perception-of-safety-day', 'resident-survey-perception-of-safety-evening', 'resident-survey-police-confidence', 'resident-survey-harassment-hate-crime', 'traffic-incidents', 'population-by-sex', 'population-by-age', 'household-composition', 'country-of-birth', 'passports-held', 'main-language', 'english-proficiency', 'ethnicity', 'religion', 'sexual-orientation', 'gender-identity', 'working-age-population', 'types-of-industry', 'qualifications', 'weekly-earnings-by-sex', 'earning-a-living-wage', 'unemployment-by-sex-and-ethnicity', 'unemployment-benefit-claimants', 'distance-to-work', 'business-creation-rate', 'business-closure-rate', 'non-domestic-rate-collection', 'early-years-providers', 'early-years-ofsted-ratings', 'early-years-areas-of-learning-performance', 'key-stage-2-performance', 'key-stage-4-performance', 'key-stage-4-performance-by-ethnicity', 'key-stage-4-performance-gap', 'key-stage-5-progression', 'neet-16-17-year-olds', 'education-funding', 'tenure-type', 'dwelling-type', 'house-prices-londonengland', 'house-prices-lambeth', 'council-tax-bands', 'public-transport-accessibility', 'road-traffic', 'resident-survey-results---council-satisfaction-of-life', 'resident-survey-results---council-runs-things', 'resident-survey-results---council-value', 'resident-survey-results---council-informed', 'resident-survey-results---council-influence-decisions', 'resident-survey-results---improving-the-area', 'resident-survey-results---top3improve', 'resident-survey-results---local-area-diffbackgrounds', 'resident-survey-results---need-help', 'resident-survey-results---work-together', 'internet-users', 'resident-survey-results---financial', 'resident-survey-results---payforfood', 'resident-survey-results---payforenergy', 'resident-survey-results---payforrent', 'poverty-rate-londonengland', 'poverty-rate-lambeth', 'children-in-low-income-households-BHC-Lambeth', 'children-in-low-income-households-BHC-London', 'children-in-low-income-households-AHC-Lambeth', 'children-in-low-income-households-AHC-London', 'pension-credit', 'census-measures-of-deprivation', 'electoral-registration', 'total-election-turnout-londonlambeth', 'total-election-turnout-lambethwards', 'total-election-turnout-england'])"
      ]
     },
     "execution_count": 1028,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3b0d88",
   "metadata": {},
   "source": [
    "## Import last year data (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd53f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\Data\\Ambition 1\\Health and Wellbeing\\res_survey_2022_filt.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:159: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  surv_sat_f.iloc[:, 1:] = surv_sat_f.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:172: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  surv_sat_f['Question'] = surv_sat_f['Question'].str.replace(r\"\\.\", \" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\Data\\Ambition 2\\Crime, Safety & Justice\\MPS_MonthlyCrimeDashboard_TNOCrimeData22-23.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\3850455025.py:30: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  lydataframes[variable_name] = pd.read_csv(file_path, header=None, skiprows=skip, encoding = encoding)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file successfully read with encoding: utf-8\n",
      "..\\Data\\Ambition 2\\Crime, Safety & Justice\\MPS_MonthlyCrimeDashboard_OtherCrimeData22-23.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\3850455025.py:30: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  lydataframes[variable_name] = pd.read_csv(file_path, header=None, skiprows=skip, encoding = encoding)\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\3850455025.py:30: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  lydataframes[variable_name] = pd.read_csv(file_path, header=None, skiprows=skip, encoding = encoding)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file successfully read with encoding: utf-8\n",
      "..\\Data\\Ambition 2\\Crime, Safety & Justice\\MPS_MonthlyCrimeDashboard_OtherCrimeData22-23.csv\n",
      "CSV file successfully read with encoding: utf-8\n",
      "..\\Data\\Ambition 2\\Crime, Safety & Justice\\MPS_MonthlyCrimeDashboard_OtherCrimeData22-23.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\3850455025.py:30: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  lydataframes[variable_name] = pd.read_csv(file_path, header=None, skiprows=skip, encoding = encoding)\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\3850455025.py:30: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  lydataframes[variable_name] = pd.read_csv(file_path, header=None, skiprows=skip, encoding = encoding)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file successfully read with encoding: utf-8\n",
      "..\\Data\\Ambition 2\\Crime, Safety & Justice\\MPS_MonthlyCrimeDashboard_OtherCrimeData22-23.csv\n",
      "CSV file successfully read with encoding: utf-8\n",
      "..\\Data\\Ambition 2\\Crime, Safety & Justice\\MPS_MonthlyCrimeDashboard_TNOCrimeData22-23.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\3850455025.py:30: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  lydataframes[variable_name] = pd.read_csv(file_path, header=None, skiprows=skip, encoding = encoding)\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:159: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  surv_sat_f.iloc[:, 1:] = surv_sat_f.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:172: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  surv_sat_f['Question'] = surv_sat_f['Question'].str.replace(r\"\\.\", \" \")\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:159: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  surv_sat_f.iloc[:, 1:] = surv_sat_f.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:172: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  surv_sat_f['Question'] = surv_sat_f['Question'].str.replace(r\"\\.\", \" \")\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:159: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  surv_sat_f.iloc[:, 1:] = surv_sat_f.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:172: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  surv_sat_f['Question'] = surv_sat_f['Question'].str.replace(r\"\\.\", \" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file successfully read with encoding: utf-8\n",
      "..\\Data\\Ambition 2\\Crime, Safety & Justice\\res_survey_2022_filt.xlsx\n",
      "..\\Data\\Ambition 2\\Crime, Safety & Justice\\res_survey_2022_filt.xlsx\n",
      "..\\Data\\Ambition 2\\Crime, Safety & Justice\\res_survey_2022_filt.xlsx\n",
      "..\\Data\\Ambition 3\\Jobs, earnings, and businesses\\local units type 2022 NOMIS.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JKim\\AppData\\Local\\anaconda3\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "C:\\Users\\JKim\\AppData\\Local\\anaconda3\\Lib\\site-packages\\openpyxl\\styles\\stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\Data\\Ambition 3\\Jobs, earnings, and businesses\\Qualifications NOMIS 2022.xlsx\n",
      "..\\Data\\Ambition 3\\Jobs, earnings, and businesses\\Work Geography LWF Table 7 LWF.1b   lwfmgx 2022.xls\n",
      "..\\Data\\Ambition 3\\Jobs, earnings, and businesses\\Unemployment 16+ Sex and Ethnicity 2022.xlsx\n",
      "..\\Data\\Ambition 3\\Community\\res_survey_2022_filt.xlsx\n",
      "..\\Data\\Ambition 3\\Community\\res_survey_2022_filt.xlsx\n",
      "..\\Data\\Ambition 3\\Community\\res_survey_2022_filt.xlsx\n",
      "..\\Data\\Ambition 3\\Community\\res_survey_2022_filt.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:159: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  surv_sat_f.iloc[:, 1:] = surv_sat_f.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:172: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  surv_sat_f['Question'] = surv_sat_f['Question'].str.replace(r\"\\.\", \" \")\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:159: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  surv_sat_f.iloc[:, 1:] = surv_sat_f.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:172: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  surv_sat_f['Question'] = surv_sat_f['Question'].str.replace(r\"\\.\", \" \")\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:159: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  surv_sat_f.iloc[:, 1:] = surv_sat_f.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:172: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  surv_sat_f['Question'] = surv_sat_f['Question'].str.replace(r\"\\.\", \" \")\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:159: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  surv_sat_f.iloc[:, 1:] = surv_sat_f.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:172: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  surv_sat_f['Question'] = surv_sat_f['Question'].str.replace(r\"\\.\", \" \")\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:159: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  surv_sat_f.iloc[:, 1:] = surv_sat_f.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:172: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  surv_sat_f['Question'] = surv_sat_f['Question'].str.replace(r\"\\.\", \" \")\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:159: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  surv_sat_f.iloc[:, 1:] = surv_sat_f.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:172: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  surv_sat_f['Question'] = surv_sat_f['Question'].str.replace(r\"\\.\", \" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\Data\\Ambition 3\\Community\\res_survey_2022_filt.xlsx\n",
      "..\\Data\\Ambition 3\\Community\\res_survey_2022_filt.xlsx\n",
      "..\\Data\\Ambition 3\\Community\\res_survey_2022_filt.xlsx\n",
      "..\\Data\\Ambition 3\\Community\\res_survey_2022_filt.xlsx\n",
      "..\\Data\\Golden Thread\\res_survey_2022_filt.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:159: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  surv_sat_f.iloc[:, 1:] = surv_sat_f.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:172: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  surv_sat_f['Question'] = surv_sat_f['Question'].str.replace(r\"\\.\", \" \")\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:159: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  surv_sat_f.iloc[:, 1:] = surv_sat_f.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:172: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  surv_sat_f['Question'] = surv_sat_f['Question'].str.replace(r\"\\.\", \" \")\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:159: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  surv_sat_f.iloc[:, 1:] = surv_sat_f.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:172: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  surv_sat_f['Question'] = surv_sat_f['Question'].str.replace(r\"\\.\", \" \")\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:159: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  surv_sat_f.iloc[:, 1:] = surv_sat_f.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:172: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  surv_sat_f['Question'] = surv_sat_f['Question'].str.replace(r\"\\.\", \" \")\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:159: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  surv_sat_f.iloc[:, 1:] = surv_sat_f.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:172: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  surv_sat_f['Question'] = surv_sat_f['Question'].str.replace(r\"\\.\", \" \")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\Data\\Golden Thread\\res_survey_2022_filt.xlsx\n",
      "..\\Data\\Golden Thread\\res_survey_2022_filt.xlsx\n",
      "..\\Data\\Golden Thread\\Electoral data - Local-Elections - May 2018.ods\n"
     ]
    }
   ],
   "source": [
    "lydataframes = {}\n",
    "# Iterate over the rows to get the file paths\n",
    "for index, row in data_sources.iterrows():\n",
    "    if row['exported?'] == 'y': # comment out when re-importing everything\n",
    "        continue\n",
    "    if pd.isna(row['Previous year File Name']) or row['File Name'] == row['Previous year File Name']:\n",
    "        continue\n",
    "    if row['Ambition'] == 'Golden Thread':\n",
    "        ambition_folder = '..\\Data\\Golden Thread\\\\'\n",
    "    else:\n",
    "        ambition_folder = '..\\Data\\Ambition '+ str(row['Ambition']) + '\\\\' + str(row['Section'])\n",
    "    \n",
    "    file_name = str(row['Previous year File Name'])\n",
    "    variable_name = 'lastyear' + row['Internal link suffix']\n",
    "    if 'Previous year sheet' in row and pd.notna(row['Previous year sheet']):\n",
    "        sheet_name = str(row['Previous year sheet'])\n",
    "    else:\n",
    "        sheet_name = str(row['Sheet']) if 'Sheet' in row and pd.notna(row['Sheet']) else 0\n",
    "    skip = int(row['Skip rows']) if 'Skip rows' in row and pd.notna(row['Skip rows']) else None\n",
    "    numrows = int(row['nrows']) if 'nrows' in row and pd.notna(row['nrows']) else None\n",
    "    file_path = os.path.join(ambition_folder, file_name)\n",
    "    print(file_path)\n",
    "    \n",
    "    # Load the data (example for CSV)\n",
    "    if file_path.endswith('.csv'):\n",
    "        # Try reading the CSV file with different encodings\n",
    "        encodings_to_try = ['utf-8', 'latin1', 'ISO-8859-1', 'cp1252', 'utf-16']\n",
    "        for encoding in encodings_to_try:\n",
    "            try:\n",
    "                lydataframes[variable_name] = pd.read_csv(file_path, header=None, skiprows=skip, encoding = encoding)\n",
    "                print(f\"CSV file successfully read with encoding: {encoding}\")\n",
    "                break  # Stop trying encodings if successful\n",
    "            except UnicodeDecodeError:\n",
    "                print(f\"Failed to read CSV file with encoding: {encoding}\") \n",
    "        \n",
    "        # Perform operations on the data\n",
    "    elif file_path.endswith('.xlsx') or file_path.endswith('.xls'):\n",
    "        lydataframes[variable_name] = pd.read_excel(file_path, sheet_name = sheet_name, header=None, \n",
    "                                                  skiprows=skip, nrows=numrows)\n",
    "    elif file_path.endswith('.ods'):\n",
    "        lydataframes[variable_name] = pd.read_excel(file_path, engine = 'odf', sheet_name = sheet_name, header=None, skiprows=skip)\n",
    "        # Perform operations on the data\n",
    "    if row['Previous year File Name'] == 'res_survey_2022_filt.xlsx':\n",
    "        lydataframes[variable_name] = create_surv_q_df2022(lydataframes[variable_name])\n",
    "    elif 'OtherCrime' in row['Previous year File Name']:\n",
    "        lydataframes[variable_name] = firstrowtocolname(lydataframes[variable_name])\n",
    "        column_mapping = {'Crime Type': 'Offence Group', 'Crime Subtype':'Offence Subgroup', 'Area Name' : 'Area name'}\n",
    "        lydataframes[variable_name] = lydataframes[variable_name].rename(columns=column_mapping)\n",
    "    else:\n",
    "        lydataframes[variable_name] = firstrowtocolname(lydataframes[variable_name])\n",
    "\n",
    "# uncomment when running everything again\n",
    "    if row['Source organisation'] == 'Fingertips':\n",
    "        dataframes[variable_name]= fingertipsclean(dataframes[variable_name])\n",
    "        converttojson(dataframes[variable_name], variable_name)\n",
    "    elif row['Source organisation'] == 'ONS':\n",
    "        lydataframes[variable_name] = lydataframes[variable_name][:-3] #remove last three rows\n",
    "        lydataframes[variable_name] = lydataframes[variable_name].dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1032,
   "id": "c66d4f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lastyearwellbeing---resident-survey-worthwhile', 'lastyearwellbeing---resident-survey-anxiety', 'lastyeardrug-and-alcohol-misuse', 'lastyearoverall-crime-rate', 'lastyearviolent-crime-rate', 'lastyearknife-crime-rate', 'lastyearknife-crime-rate-with-victims-younger-than-25', 'lastyeardomestic-abuse-crime-rate', 'lastyearhate-crime-rate', 'lastyeardrug-related-crime-rate', 'lastyeardomestic-burglary-crime-rate', 'lastyearresident-survey-perception-of-safety-day', 'lastyearresident-survey-perception-of-safety-evening', 'lastyearresident-survey-police-confidence', 'lastyeartypes-of-industry', 'lastyearqualifications', 'lastyearweekly-earnings-by-sex', 'lastyearearning-a-living-wage', 'lastyearunemployment-by-sex-and-ethnicity', 'lastyearresident-survey-results---council-satisfaction-of-life', 'lastyearresident-survey-results---council-runs-things', 'lastyearresident-survey-results---council-value', 'lastyearresident-survey-results---council-informed', 'lastyearresident-survey-results---council-influence-decisions', 'lastyearresident-survey-results---improving-the-area', 'lastyearresident-survey-results---top3improve', 'lastyearresident-survey-results---local-area-diffbackgrounds', 'lastyearresident-survey-results---need-help', 'lastyearresident-survey-results---work-together', 'lastyearresident-survey-results---financial', 'lastyearresident-survey-results---payforfood', 'lastyearresident-survey-results---payforenergy', 'lastyearresident-survey-results---payforrent', 'lastyeartotal-election-turnout-londonlambeth', 'lastyeartotal-election-turnout-lambethwards', 'lastyeartotal-election-turnout-england'])"
      ]
     },
     "execution_count": 1032,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lydataframes.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff911ebe",
   "metadata": {},
   "source": [
    "# Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1122,
   "id": "b978bc91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['childhood-vaccinations', 'healthy-weight---reception', 'healthy-weight---year-6', 'good-level-of-development---age-5', 'wellbeing---resident-survey-worthwhile', 'wellbeing---resident-survey-anxiety', 'personal-wellbeing', 'sexual-health', 'physical-exercise', 'healthy-weight', 'smoking', 'high-blood-pressure', 'drug-and-alcohol-misuse', 'diabetes', 'depression', 'coronary-heart-disease', 'male-life-expectancy-at-birth', 'female-life-expectancy-at-birth', 'male-healthy-life-expectancy', 'female-healthy-life-expectancy', 'deaths-under-75-from-preventable-causes', 'preventable-mortality---cancer', 'preventable-mortality---cardiovascular-disease', 'preventable-mortality---liver-disease', 'preventable-mortality---respiratory-disease', 'greenhouse-gas-emissions', 'recycling-rates', 'energy-performance-certificate-ratings-Lambeth', 'energy-performance-certificate-ratings-London', 'energy-performance-certificate-ratings-England', 'solar-panel-installations', 'access-to-public-green-space-england', 'access-to-public-green-space-london', 'access-to-public-green-space-lambeth', 'tree-canopy-cover', 'method-of-travel-to-work', 'overall-crime-rate', 'violent-crime-rate', 'knife-crime-rate', 'knife-crime-rate-with-victims-younger-than-25', 'domestic-abuse-crime-rate', 'hate-crime-rate', 'drug-related-crime-rate', 'domestic-burglary-crime-rate', 'anti-social-behaviour', 'reoffending-rates', 'stop-and-search', 'public-perception-of-police', 'resident-survey-perception-of-safety-day', 'resident-survey-perception-of-safety-evening', 'resident-survey-police-confidence', 'resident-survey-harassment-hate-crime', 'traffic-incidents', 'population-by-sex', 'population-by-age', 'household-composition', 'country-of-birth', 'passports-held', 'main-language', 'english-proficiency', 'ethnicity', 'religion', 'sexual-orientation', 'gender-identity', 'working-age-population', 'types-of-industry', 'qualifications', 'weekly-earnings-by-sex', 'earning-a-living-wage', 'unemployment-by-sex-and-ethnicity', 'unemployment-benefit-claimants', 'distance-to-work', 'business-creation-rate', 'business-closure-rate', 'non-domestic-rate-collection', 'early-years-providers', 'early-years-ofsted-ratings', 'early-years-areas-of-learning-performance', 'key-stage-2-performance', 'key-stage-4-performance', 'key-stage-4-performance-by-ethnicity', 'key-stage-4-performance-gap', 'key-stage-5-progression', 'neet-16-17-year-olds', 'education-funding', 'tenure-type', 'dwelling-type', 'house-prices-londonengland', 'house-prices-lambeth', 'council-tax-bands', 'public-transport-accessibility', 'road-traffic', 'resident-survey-results---council-satisfaction-of-life', 'resident-survey-results---council-runs-things', 'resident-survey-results---council-value', 'resident-survey-results---council-informed', 'resident-survey-results---council-influence-decisions', 'resident-survey-results---improving-the-area', 'resident-survey-results---top3improve', 'resident-survey-results---local-area-diffbackgrounds', 'resident-survey-results---need-help', 'resident-survey-results---work-together', 'internet-users', 'resident-survey-results---financial', 'resident-survey-results---payforfood', 'resident-survey-results---payforenergy', 'resident-survey-results---payforrent', 'poverty-rate-londonengland', 'poverty-rate-lambeth', 'children-in-low-income-households-BHC-Lambeth', 'children-in-low-income-households-BHC-London', 'children-in-low-income-households-AHC-Lambeth', 'children-in-low-income-households-AHC-London', 'pension-credit', 'census-measures-of-deprivation', 'electoral-registration', 'total-election-turnout-londonlambeth', 'total-election-turnout-lambethwards', 'total-election-turnout-england'])"
      ]
     },
     "execution_count": 1122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1179,
   "id": "004053e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Table 3: Number and Percentage of Children (aged under 16) living in Relative low income families, Local Authority, FYE 2015 to 2023, United Kingdom</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Back to Contents</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This worksheet contains one table. Some cells ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Some shorthand is used in this table, [p] = pr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This table shows children aged 0 to 15 years o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FYE = Financial Years Ending.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>Fermanagh and Omagh</td>\n",
       "      <td>N09000006</td>\n",
       "      <td>5035</td>\n",
       "      <td>5049</td>\n",
       "      <td>4968</td>\n",
       "      <td>4545</td>\n",
       "      <td>4721</td>\n",
       "      <td>4920</td>\n",
       "      <td>5543</td>\n",
       "      <td>4819</td>\n",
       "      <td>4935</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>Lisburn and Castlereagh</td>\n",
       "      <td>N09000007</td>\n",
       "      <td>3742</td>\n",
       "      <td>3729</td>\n",
       "      <td>3732</td>\n",
       "      <td>3458</td>\n",
       "      <td>3737</td>\n",
       "      <td>4075</td>\n",
       "      <td>4274</td>\n",
       "      <td>3708</td>\n",
       "      <td>3893</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>Mid and East Antrim</td>\n",
       "      <td>N09000008</td>\n",
       "      <td>4731</td>\n",
       "      <td>4948</td>\n",
       "      <td>4841</td>\n",
       "      <td>4466</td>\n",
       "      <td>4709</td>\n",
       "      <td>5032</td>\n",
       "      <td>5244</td>\n",
       "      <td>4488</td>\n",
       "      <td>4695</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>Mid Ulster</td>\n",
       "      <td>N09000009</td>\n",
       "      <td>6496</td>\n",
       "      <td>6536</td>\n",
       "      <td>6184</td>\n",
       "      <td>5550</td>\n",
       "      <td>5826</td>\n",
       "      <td>6143</td>\n",
       "      <td>7107</td>\n",
       "      <td>6263</td>\n",
       "      <td>6491</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>Newry, Mourne and Down</td>\n",
       "      <td>N09000010</td>\n",
       "      <td>8677</td>\n",
       "      <td>8797</td>\n",
       "      <td>8641</td>\n",
       "      <td>8283</td>\n",
       "      <td>8723</td>\n",
       "      <td>8734</td>\n",
       "      <td>9780</td>\n",
       "      <td>8680</td>\n",
       "      <td>9002</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>371 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0   Table 3: Number and Percentage of Children (aged under 16) living in Relative low income families, Local Authority, FYE 2015 to 2023, United Kingdom  \\\n",
       "0                                     Back to Contents                                                                                                     \n",
       "1    This worksheet contains one table. Some cells ...                                                                                                     \n",
       "2    Some shorthand is used in this table, [p] = pr...                                                                                                     \n",
       "3    This table shows children aged 0 to 15 years o...                                                                                                     \n",
       "4                        FYE = Financial Years Ending.                                                                                                     \n",
       "..                                                 ...                                                                                                     \n",
       "366                                Fermanagh and Omagh                                                                                                     \n",
       "367                            Lisburn and Castlereagh                                                                                                     \n",
       "368                                Mid and East Antrim                                                                                                     \n",
       "369                                         Mid Ulster                                                                                                     \n",
       "370                             Newry, Mourne and Down                                                                                                     \n",
       "\n",
       "0          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN  \\\n",
       "0          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN   \n",
       "1          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN   \n",
       "2          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN   \n",
       "3          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN   \n",
       "4          NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN   \n",
       "..         ...   ...   ...   ...   ...   ...   ...   ...   ...   ...    ...   \n",
       "366  N09000006  5035  5049  4968  4545  4721  4920  5543  4819  4935  0.203   \n",
       "367  N09000007  3742  3729  3732  3458  3737  4075  4274  3708  3893  0.135   \n",
       "368  N09000008  4731  4948  4841  4466  4709  5032  5244  4488  4695  0.181   \n",
       "369  N09000009  6496  6536  6184  5550  5826  6143  7107  6263  6491  0.197   \n",
       "370  N09000010  8677  8797  8641  8283  8723  8734  9780  8680  9002   0.22   \n",
       "\n",
       "0      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "0      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "1      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "2      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "3      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "4      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "366  0.204  0.201  0.183  0.189  0.197  0.223  0.195  0.199  \n",
       "367  0.133  0.132  0.121  0.128  0.137  0.144  0.123  0.128  \n",
       "368   0.19  0.185   0.17  0.178  0.191    0.2  0.173  0.182  \n",
       "369  0.197  0.185  0.164  0.171  0.178  0.206  0.181  0.187  \n",
       "370  0.222  0.216  0.206  0.216  0.215  0.243  0.216  0.223  \n",
       "\n",
       "[371 rows x 20 columns]"
      ]
     },
     "execution_count": 1179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes['children-in-low-income-households-BHC-Lambeth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "73b8e5d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Industry</th>\n",
       "      <th>lacu:Lambeth</th>\n",
       "      <th>country:England</th>\n",
       "      <th>gor:London</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01 : Crop and animal production, hunting and r...</td>\n",
       "      <td>10</td>\n",
       "      <td>90260</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02 : Forestry and logging</td>\n",
       "      <td>5</td>\n",
       "      <td>3420</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03 : Fishing and aquaculture</td>\n",
       "      <td>0</td>\n",
       "      <td>1725</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05 : Mining of coal and lignite</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>06 : Extraction of crude petroleum and natural...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>99 : Activities of extraterritorial organisati...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Column Total</td>\n",
       "      <td>14960</td>\n",
       "      <td>2737105</td>\n",
       "      <td>584415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>All figures are rounded to avoid disclosure. V...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>In 2015, ONS extended the coverage of business...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0                                            Industry lacu:Lambeth  \\\n",
       "0   01 : Crop and animal production, hunting and r...           10   \n",
       "1                           02 : Forestry and logging            5   \n",
       "2                        03 : Fishing and aquaculture            0   \n",
       "3                     05 : Mining of coal and lignite            0   \n",
       "4   06 : Extraction of crude petroleum and natural...            0   \n",
       "..                                                ...          ...   \n",
       "87  99 : Activities of extraterritorial organisati...            0   \n",
       "88                                       Column Total        14960   \n",
       "89                                                NaN          NaN   \n",
       "90  All figures are rounded to avoid disclosure. V...          NaN   \n",
       "91  In 2015, ONS extended the coverage of business...          NaN   \n",
       "\n",
       "0  country:England gor:London  \n",
       "0            90260        640  \n",
       "1             3420        230  \n",
       "2             1725         45  \n",
       "3               10          0  \n",
       "4              100         40  \n",
       "..             ...        ...  \n",
       "87               5          5  \n",
       "88         2737105     584415  \n",
       "89             NaN        NaN  \n",
       "90             NaN        NaN  \n",
       "91             NaN        NaN  \n",
       "\n",
       "[92 rows x 4 columns]"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes['types-of-industry'] #, 'qualifications', 'weekly-earnings-by-sex', 'earning-a-living-wage', 'unemployment-by-sex-and-ethnicity', 'unemployment-benefit-claimants', 'distance-to-work']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2220fb5c",
   "metadata": {},
   "source": [
    "# Completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1177,
   "id": "66aeb79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 'poverty-rate-AHC' saved as JSON file: Clean Data/poverty-rate-AHC.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area name</th>\n",
       "      <th>Percent</th>\n",
       "      <th>Time period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lambeth</td>\n",
       "      <td>28</td>\n",
       "      <td>2016/17-2021-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>22</td>\n",
       "      <td>2019/20 - 2021/22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>London</td>\n",
       "      <td>25</td>\n",
       "      <td>2019/20 - 2021/22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>England</td>\n",
       "      <td>22</td>\n",
       "      <td>2020/21 - 2022/23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>London</td>\n",
       "      <td>24</td>\n",
       "      <td>2020/21 - 2022/23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Area name Percent        Time period\n",
       "0   Lambeth      28    2016/17-2021-22\n",
       "1   England      22  2019/20 - 2021/22\n",
       "2    London      25  2019/20 - 2021/22\n",
       "3   England      22  2020/21 - 2022/23\n",
       "4    London      24  2020/21 - 2022/23"
      ]
     },
     "execution_count": 1177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Poverty rate AHC ------------------------------------------\n",
    "# 5year avg data from 2016/17-2021/22 excluding 2020/21\n",
    "lambethdf = dataframes['poverty-rate-lambeth']\n",
    "lambethdf=lambethdf[lambethdf['London borough']=='Lambeth'].loc[:,['London borough', 'Poverty rate (AHC)']]\n",
    "lambethdf = lambethdf.rename(columns={'London borough':'Area name', 'Poverty rate (AHC)': 'Percent'})\n",
    "lambethdf['Time period']= '2016/17-2021-22'\n",
    "lambethdf['Percent'] = int(lambethdf['Percent'].str.replace(\"%\", \"\"))\n",
    "\n",
    "df = dataframes['poverty-rate-londonengland']\n",
    "\n",
    "df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "df = df[df['Region'].isin(['London', 'England']) &\n",
    "       (df['Group']=='Total')&\n",
    "       (df['Poverty measure']=='Relative')]\n",
    "\n",
    "df = df[(df['Quantity']=='%') &\n",
    "        (df['Housing costs']=='AHC')]\n",
    "df = df.loc[:,['Region', '2019/20 - 2021/22', '2020/21 - 2022/23']]\n",
    "df\n",
    "melted_df = pd.melt(df, id_vars=['Region'], var_name='Time period', value_name='Percent')\n",
    "# \n",
    "melted_df = melted_df.rename(columns={'Region':'Area name'})\n",
    "\n",
    "combineddf = pd.concat([lambethdf, melted_df], ignore_index=True)\n",
    "converttojson(combineddf, 'poverty-rate-AHC')\n",
    "combineddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1121,
   "id": "0522b5c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 'survey_wellbeing_safety' saved as JSON file: Clean Data/survey_wellbeing_safety.json\n",
      "DataFrame 'lastyearsurvey_wellbeing_safety' saved as JSON file: Clean Data/lastyearsurvey_wellbeing_safety.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1209231986.py:15: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  surv_sat_f_safety['Response'] = surv_sat_f_safety['Response'].str.replace(r'\\[.*\\]', '')\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1209231986.py:34: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  lastyearsurv_sat_f_safety['Response'] = lastyearsurv_sat_f_safety['Response'].str.replace(r'\\[.*\\]', '')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Response</th>\n",
       "      <th>Percentage of respondents</th>\n",
       "      <th>Question</th>\n",
       "      <th>Time period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Very safe</td>\n",
       "      <td>47.9</td>\n",
       "      <td>To what extent would you say you are, or would...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fairly safe</td>\n",
       "      <td>44.2</td>\n",
       "      <td>To what extent would you say you are, or would...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not particularly safe</td>\n",
       "      <td>5.9</td>\n",
       "      <td>To what extent would you say you are, or would...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not safe at all</td>\n",
       "      <td>1.3</td>\n",
       "      <td>To what extent would you say you are, or would...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Very safe</td>\n",
       "      <td>14.7</td>\n",
       "      <td>To what extent would you say you are, or would...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fairly safe</td>\n",
       "      <td>48.5</td>\n",
       "      <td>To what extent would you say you are, or would...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Not particularly safe</td>\n",
       "      <td>24.3</td>\n",
       "      <td>To what extent would you say you are, or would...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Not safe at all</td>\n",
       "      <td>10.5</td>\n",
       "      <td>To what extent would you say you are, or would...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>8.5</td>\n",
       "      <td>To what extent do you agree or disagree that y...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tend to agree</td>\n",
       "      <td>25.6</td>\n",
       "      <td>To what extent do you agree or disagree that y...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Neither agree nor disagree</td>\n",
       "      <td>28.3</td>\n",
       "      <td>To what extent do you agree or disagree that y...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Tend to disagree</td>\n",
       "      <td>17.5</td>\n",
       "      <td>To what extent do you agree or disagree that y...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Strongly disagree</td>\n",
       "      <td>15.6</td>\n",
       "      <td>To what extent do you agree or disagree that y...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Response  Percentage of respondents  \\\n",
       "0                    Very safe                       47.9   \n",
       "1                  Fairly safe                       44.2   \n",
       "2        Not particularly safe                        5.9   \n",
       "3              Not safe at all                        1.3   \n",
       "4                    Very safe                       14.7   \n",
       "5                  Fairly safe                       48.5   \n",
       "6        Not particularly safe                       24.3   \n",
       "7              Not safe at all                       10.5   \n",
       "8               Strongly agree                        8.5   \n",
       "9                Tend to agree                       25.6   \n",
       "10  Neither agree nor disagree                       28.3   \n",
       "11            Tend to disagree                       17.5   \n",
       "12           Strongly disagree                       15.6   \n",
       "\n",
       "                                             Question  Time period  \n",
       "0   To what extent would you say you are, or would...         2022  \n",
       "1   To what extent would you say you are, or would...         2022  \n",
       "2   To what extent would you say you are, or would...         2022  \n",
       "3   To what extent would you say you are, or would...         2022  \n",
       "4   To what extent would you say you are, or would...         2022  \n",
       "5   To what extent would you say you are, or would...         2022  \n",
       "6   To what extent would you say you are, or would...         2022  \n",
       "7   To what extent would you say you are, or would...         2022  \n",
       "8   To what extent do you agree or disagree that y...         2022  \n",
       "9   To what extent do you agree or disagree that y...         2022  \n",
       "10  To what extent do you agree or disagree that y...         2022  \n",
       "11  To what extent do you agree or disagree that y...         2022  \n",
       "12  To what extent do you agree or disagree that y...         2022  "
      ]
     },
     "execution_count": 1121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perception of Safety Resident survey ----------------------------------------------------------\n",
    "q015_1 = dataframes['resident-survey-perception-of-safety-day']\n",
    "q015_2= dataframes['resident-survey-perception-of-safety-evening']\n",
    "q1y22 = dataframes['resident-survey-police-confidence']\n",
    "q2bnew22 = dataframes['resident-survey-harassment-hate-crime']\n",
    "\n",
    "# Join all DataFrames\n",
    "surv_sat_f_safety = pd.concat([q015_1, q015_2, q1y22, q2bnew22], ignore_index=True)\n",
    "\n",
    "# Add a 'Year' column with value 2023\n",
    "surv_sat_f_safety['Time period'] = 2023\n",
    "surv_sat_f_safety.drop(surv_sat_f_safety.columns[2], axis=1, inplace=True)\n",
    "\n",
    "# Remove anything between square brackets in Responses\n",
    "surv_sat_f_safety['Response'] = surv_sat_f_safety['Response'].str.replace(r'\\[.*\\]', '')\n",
    "\n",
    "# Make 'Response' an ordered categorical column with levels in the order of appearance\n",
    "surv_sat_f_safety['Response'] = pd.Categorical(surv_sat_f_safety['Response'], categories=surv_sat_f_safety['Response'].unique(), ordered=True)\n",
    "converttojson(surv_sat_f_safety,'survey_wellbeing_safety')\n",
    "surv_sat_f_safety\n",
    "\n",
    "# Last Year Perception of Safety Resident survey ----------------------------------------------------------\n",
    "q015_1 = lydataframes['lastyearresident-survey-perception-of-safety-day']\n",
    "q015_2= lydataframes['lastyearresident-survey-perception-of-safety-evening']\n",
    "q1y22 = lydataframes['lastyearresident-survey-police-confidence']\n",
    "\n",
    "# Join all DataFrames\n",
    "lastyearsurv_sat_f_safety = pd.concat([q015_1, q015_2, q1y22], ignore_index=True)\n",
    "\n",
    "# Add a 'Year' column with value 2022\n",
    "lastyearsurv_sat_f_safety['Time period'] = 2022\n",
    "\n",
    "# Remove anything between square brackets in Responses\n",
    "lastyearsurv_sat_f_safety['Response'] = lastyearsurv_sat_f_safety['Response'].str.replace(r'\\[.*\\]', '')\n",
    "\n",
    "# Make 'Response' an ordered categorical column with levels in the order of appearance\n",
    "lastyearsurv_sat_f_safety['Response'] = pd.Categorical(lastyearsurv_sat_f_safety['Response'], categories=lastyearsurv_sat_f_safety['Response'].unique(), ordered=True)\n",
    "converttojson(lastyearsurv_sat_f_safety,'lastyearsurvey_wellbeing_safety')\n",
    "lastyearsurv_sat_f_safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1109,
   "id": "d68b982f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:64: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  londondf = londondf.groupby(['Time period'], as_index=False).sum()\n"
     ]
    }
   ],
   "source": [
    "df=dataframes['overall-crime-rate']\n",
    "df = crimerate(df)\n",
    "lydf=lydataframes['lastyearoverall-crime-rate']\n",
    "lydf = crimerate(lydf)\n",
    "overallcrime = pd.concat([df, lydf], ignore_index=True)\n",
    "converttojson(overallcrime,'monthlyoverallcrimespercapita')\n",
    "overallcrime\n",
    "\n",
    "df=dataframes['hate-crime-rate']\n",
    "df = crimerate(df, 'Hate crime')\n",
    "lydf=lydataframes['lastyearhate-crime-rate']\n",
    "lydf = crimerate(lydf, 'Hate crime')\n",
    "hate = pd.concat([df, lydf], ignore_index=True)\n",
    "converttojson(hate,'monthlyhatecrimespercapita')\n",
    "hate\n",
    "\n",
    "df=dataframes['domestic-abuse-crime-rate']\n",
    "df = crimerate(df, 'Domestic Abuse')\n",
    "lydf=lydataframes['lastyeardomestic-abuse-crime-rate']\n",
    "lydf = crimerate(lydf, 'Domestic Abuse')\n",
    "abuse = pd.concat([df, lydf], ignore_index=True)\n",
    "converttojson(abuse,'monthlydomesticabusecrimespercapita')\n",
    "abuse\n",
    "\n",
    "df=dataframes['knife-crime-rate']\n",
    "df = crimerate(df, 'Knife crime')\n",
    "lydf=lydataframes['lastyearknife-crime-rate']\n",
    "lydf = crimerate(lydf, 'Knife crime')\n",
    "knives = pd.concat([df, lydf], ignore_index=True)\n",
    "converttojson(knives,'monthlyknifecrimespercapita')\n",
    "knives\n",
    "\n",
    "df=dataframes['knife-crime-rate']\n",
    "df = crimerate(df, 'Knife crime', \"Knife Injury Victims (non DA 1-24)\")\n",
    "lydf=lydataframes['lastyearknife-crime-rate']\n",
    "lydf = crimerate(lydf, 'Knife crime', \"Knife Injury Victims (non DA 1-24)\")\n",
    "knives = pd.concat([df, lydf], ignore_index=True)\n",
    "converttojson(knives,'monthlyknifecrimesvictimsU25percapita')\n",
    "knives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1112,
   "id": "4351447a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:64: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  londondf = londondf.groupby(['Time period'], as_index=False).sum()\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:64: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  londondf = londondf.groupby(['Time period'], as_index=False).sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 'monthlyviolentcrimespercapita' saved as JSON file: Clean Data/monthlyviolentcrimespercapita.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:64: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  londondf = londondf.groupby(['Time period'], as_index=False).sum()\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:64: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  londondf = londondf.groupby(['Time period'], as_index=False).sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 'monthlydomesticburglarypercapita' saved as JSON file: Clean Data/monthlydomesticburglarypercapita.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:64: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  londondf = londondf.groupby(['Time period'], as_index=False).sum()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 'monthlydrugoffensespercapita' saved as JSON file: Clean Data/monthlydrugoffensespercapita.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1378232835.py:64: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  londondf = londondf.groupby(['Time period'], as_index=False).sum()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AreaName</th>\n",
       "      <th>Population</th>\n",
       "      <th>Time period</th>\n",
       "      <th>Count</th>\n",
       "      <th>Offences per 1,000 people</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lambeth</td>\n",
       "      <td>317654</td>\n",
       "      <td>2023-04</td>\n",
       "      <td>104</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lambeth</td>\n",
       "      <td>317654</td>\n",
       "      <td>2023-05</td>\n",
       "      <td>116</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lambeth</td>\n",
       "      <td>317654</td>\n",
       "      <td>2023-06</td>\n",
       "      <td>104</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lambeth</td>\n",
       "      <td>317654</td>\n",
       "      <td>2023-07</td>\n",
       "      <td>113</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lambeth</td>\n",
       "      <td>317654</td>\n",
       "      <td>2023-08</td>\n",
       "      <td>125</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>London</td>\n",
       "      <td>8799728</td>\n",
       "      <td>2022-11</td>\n",
       "      <td>3531</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>London</td>\n",
       "      <td>8799728</td>\n",
       "      <td>2022-12</td>\n",
       "      <td>2899</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>London</td>\n",
       "      <td>8799728</td>\n",
       "      <td>2023-01</td>\n",
       "      <td>3738</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>London</td>\n",
       "      <td>8799728</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>3047</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>London</td>\n",
       "      <td>8799728</td>\n",
       "      <td>2023-03</td>\n",
       "      <td>3192</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0   AreaName  Population Time period  Count  Offences per 1,000 people\n",
       "0    Lambeth      317654     2023-04    104                        0.3\n",
       "1    Lambeth      317654     2023-05    116                        0.4\n",
       "2    Lambeth      317654     2023-06    104                        0.3\n",
       "3    Lambeth      317654     2023-07    113                        0.4\n",
       "4    Lambeth      317654     2023-08    125                        0.4\n",
       "..       ...         ...         ...    ...                        ...\n",
       "564   London     8799728     2022-11   3531                        0.4\n",
       "565   London     8799728     2022-12   2899                        0.3\n",
       "566   London     8799728     2023-01   3738                        0.4\n",
       "567   London     8799728     2023-02   3047                        0.3\n",
       "568   London     8799728     2023-03   3192                        0.4\n",
       "\n",
       "[569 rows x 5 columns]"
      ]
     },
     "execution_count": 1112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "violentcrime = crimerate(dataframes['violent-crime-rate'], 'Violence Against the Person')\n",
    "lyviolentcrime = crimerate(lydataframes['lastyearviolent-crime-rate'], 'Violence Against the Person')\n",
    "violentcrime = pd.concat([violentcrime, lyviolentcrime], ignore_index=True)\n",
    "converttojson(violentcrime,'monthlyviolentcrimespercapita')\n",
    "lyviolentcrime\n",
    "\n",
    "burglar2023 = crimerate(dataframes['domestic-burglary-crime-rate'], 'Burglary', 'Domestic Burglary')\n",
    "burglar2022 = crimerate(lydataframes['lastyeardomestic-burglary-crime-rate'], 'Burglary', 'Domestic Burglary')\n",
    "burglar = pd.concat([burglar2023, burglar2022], ignore_index=True)\n",
    "converttojson(burglar,'monthlydomesticburglarypercapita')\n",
    "burglar\n",
    "\n",
    "drugs2023 = crimerate(dataframes['drug-and-alcohol-misuse'], 'Drug Offences')\n",
    "drugs2022 = crimerate(lydataframes['lastyeardrug-and-alcohol-misuse'], 'Drug Offences')\n",
    "drugs = pd.concat([drugs2023, drugs2022], ignore_index=True)\n",
    "converttojson(drugs,'monthlydrugoffensespercapita')\n",
    "drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "id": "3939465b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 'election2018-22' saved as JSON file: Clean Data/election2018-22.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\2666941033.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfwards['Ballot box turnout'] = dfwards.iloc[:,2].astype(int)/ dfwards.iloc[:,1].astype(int)\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\2666941033.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  election_df = election_df.append(dfengland, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AreaName</th>\n",
       "      <th>Electorate</th>\n",
       "      <th>Ballot papers at the count</th>\n",
       "      <th>Ballot box turnout</th>\n",
       "      <th>Time period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lambeth</td>\n",
       "      <td>226899</td>\n",
       "      <td>71925</td>\n",
       "      <td>31.7</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>London</td>\n",
       "      <td>6036183</td>\n",
       "      <td>2151194</td>\n",
       "      <td>35.6</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brixton Acre Lane</td>\n",
       "      <td>11042</td>\n",
       "      <td>3271</td>\n",
       "      <td>29.6</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brixton North</td>\n",
       "      <td>11084</td>\n",
       "      <td>2869</td>\n",
       "      <td>25.9</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brixton Rush Common</td>\n",
       "      <td>10646</td>\n",
       "      <td>3306</td>\n",
       "      <td>31.1</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Brixton Windrush</td>\n",
       "      <td>6845</td>\n",
       "      <td>1858</td>\n",
       "      <td>27.1</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Clapham Common &amp; Abbeville</td>\n",
       "      <td>7357</td>\n",
       "      <td>2908</td>\n",
       "      <td>39.5</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Clapham East</td>\n",
       "      <td>7439</td>\n",
       "      <td>1744</td>\n",
       "      <td>23.4</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Clapham Park</td>\n",
       "      <td>9710</td>\n",
       "      <td>2497</td>\n",
       "      <td>25.7</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Clapham Town</td>\n",
       "      <td>11514</td>\n",
       "      <td>3562</td>\n",
       "      <td>30.9</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gipsy Hill</td>\n",
       "      <td>7792</td>\n",
       "      <td>2919</td>\n",
       "      <td>37.5</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Herne Hill &amp; Loughborough Junction</td>\n",
       "      <td>11208</td>\n",
       "      <td>4670</td>\n",
       "      <td>41.7</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Kennington</td>\n",
       "      <td>11498</td>\n",
       "      <td>3967</td>\n",
       "      <td>34.5</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Knight's Hill</td>\n",
       "      <td>11677</td>\n",
       "      <td>3707</td>\n",
       "      <td>31.7</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Myatt's Fields</td>\n",
       "      <td>8138</td>\n",
       "      <td>2342</td>\n",
       "      <td>28.8</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Oval</td>\n",
       "      <td>8998</td>\n",
       "      <td>2783</td>\n",
       "      <td>30.9</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>St Martin's</td>\n",
       "      <td>7204</td>\n",
       "      <td>2161</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Stockwell East</td>\n",
       "      <td>7223</td>\n",
       "      <td>2162</td>\n",
       "      <td>29.9</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Stockwell West &amp; Larkhall</td>\n",
       "      <td>11730</td>\n",
       "      <td>3173</td>\n",
       "      <td>27.1</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Streatham Common &amp; Vale</td>\n",
       "      <td>11872</td>\n",
       "      <td>3402</td>\n",
       "      <td>28.7</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Streatham Hill East</td>\n",
       "      <td>7152</td>\n",
       "      <td>2213</td>\n",
       "      <td>30.9</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Streatham Hill West &amp; Thornton</td>\n",
       "      <td>7934</td>\n",
       "      <td>3323</td>\n",
       "      <td>41.9</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Streatham St Leonard's</td>\n",
       "      <td>10754</td>\n",
       "      <td>3655</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Streatham Wells</td>\n",
       "      <td>7123</td>\n",
       "      <td>2323</td>\n",
       "      <td>32.6</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Vauxhall</td>\n",
       "      <td>6474</td>\n",
       "      <td>1729</td>\n",
       "      <td>26.7</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Waterloo &amp; South Bank</td>\n",
       "      <td>6158</td>\n",
       "      <td>2003</td>\n",
       "      <td>32.5</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>West Dulwich</td>\n",
       "      <td>8327</td>\n",
       "      <td>3378</td>\n",
       "      <td>40.6</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>England</td>\n",
       "      <td>22376330</td>\n",
       "      <td>7520663</td>\n",
       "      <td>33.6</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Lambeth</td>\n",
       "      <td>231772</td>\n",
       "      <td>78737</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>London</td>\n",
       "      <td>5944784</td>\n",
       "      <td>2320895</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>England</td>\n",
       "      <td>21476493</td>\n",
       "      <td>7461042</td>\n",
       "      <td>34.7</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              AreaName Electorate Ballot papers at the count  \\\n",
       "0                              Lambeth     226899                      71925   \n",
       "1                               London    6036183                    2151194   \n",
       "2                    Brixton Acre Lane      11042                       3271   \n",
       "3                        Brixton North      11084                       2869   \n",
       "4                  Brixton Rush Common      10646                       3306   \n",
       "5                     Brixton Windrush       6845                       1858   \n",
       "6           Clapham Common & Abbeville       7357                       2908   \n",
       "7                         Clapham East       7439                       1744   \n",
       "8                         Clapham Park       9710                       2497   \n",
       "9                         Clapham Town      11514                       3562   \n",
       "10                          Gipsy Hill       7792                       2919   \n",
       "11  Herne Hill & Loughborough Junction      11208                       4670   \n",
       "12                          Kennington      11498                       3967   \n",
       "13                       Knight's Hill      11677                       3707   \n",
       "14                      Myatt's Fields       8138                       2342   \n",
       "15                                Oval       8998                       2783   \n",
       "16                         St Martin's       7204                       2161   \n",
       "17                      Stockwell East       7223                       2162   \n",
       "18           Stockwell West & Larkhall      11730                       3173   \n",
       "19             Streatham Common & Vale      11872                       3402   \n",
       "20                 Streatham Hill East       7152                       2213   \n",
       "21      Streatham Hill West & Thornton       7934                       3323   \n",
       "22              Streatham St Leonard's      10754                       3655   \n",
       "23                     Streatham Wells       7123                       2323   \n",
       "24                            Vauxhall       6474                       1729   \n",
       "25               Waterloo & South Bank       6158                       2003   \n",
       "26                        West Dulwich       8327                       3378   \n",
       "27                             England   22376330                    7520663   \n",
       "28                             Lambeth     231772                      78737   \n",
       "29                              London    5944784                    2320895   \n",
       "30                             England   21476493                    7461042   \n",
       "\n",
       "    Ballot box turnout  Time period  \n",
       "0                 31.7         2022  \n",
       "1                 35.6         2022  \n",
       "2                 29.6         2022  \n",
       "3                 25.9         2022  \n",
       "4                 31.1         2022  \n",
       "5                 27.1         2022  \n",
       "6                 39.5         2022  \n",
       "7                 23.4         2022  \n",
       "8                 25.7         2022  \n",
       "9                 30.9         2022  \n",
       "10                37.5         2022  \n",
       "11                41.7         2022  \n",
       "12                34.5         2022  \n",
       "13                31.7         2022  \n",
       "14                28.8         2022  \n",
       "15                30.9         2022  \n",
       "16                30.0         2022  \n",
       "17                29.9         2022  \n",
       "18                27.1         2022  \n",
       "19                28.7         2022  \n",
       "20                30.9         2022  \n",
       "21                41.9         2022  \n",
       "22                34.0         2022  \n",
       "23                32.6         2022  \n",
       "24                26.7         2022  \n",
       "25                32.5         2022  \n",
       "26                40.6         2022  \n",
       "27                33.6         2022  \n",
       "28                34.0         2018  \n",
       "29                39.0         2018  \n",
       "30                34.7         2018  "
      ]
     },
     "execution_count": 821,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2018 election\n",
    "df = lydataframes['lastyeartotal-election-turnout-londonlambeth']\n",
    "df = df.iloc[1:33,[1,2,6,7]]\n",
    "df = firstrowtocolname(df)\n",
    "column_mapping = {df.columns[0]: 'AreaName'}\n",
    "df = df.rename(columns=column_mapping)\n",
    "lydf = df[df['AreaName']=='Lambeth']\n",
    "\n",
    "dflondon = lydataframes['lastyeartotal-election-turnout-lambethwards']\n",
    "dflondon = dflondon.iloc[1:,[1,3,5,8,9]]\n",
    "dflondon = firstrowtocolname(dflondon)\n",
    "\n",
    "dflondon = dflondon[dflondon['Ward'].isin(['Total London Boroughs', 'England'])]\n",
    "\n",
    "dflondon=dflondon.drop(dflondon.columns[[1]], axis=1, inplace=False)\n",
    "dflondon\n",
    "\n",
    "column_mapping = {dflondon.columns[0]: 'AreaName'}\n",
    "dflondon = dflondon.rename(columns=column_mapping)\n",
    "election_df2018 = pd.concat([lydf, dflondon], ignore_index=True)\n",
    "election_df2018['Time period'] = 2018\n",
    "column_mapping = {election_df2018.columns[1] :'Electorate',\n",
    "                  election_df2018.columns[2] :'Ballot papers at the count',\n",
    "                  election_df2018.columns[3]: 'Ballot box turnout'}\n",
    "election_df2018 = election_df2018.rename(columns=column_mapping)\n",
    "\n",
    "# 2022 election ---------------------------------------------------------------\n",
    "df = dataframes['total-election-turnout-londonlambeth']\n",
    "df = df.iloc[:2,:4]\n",
    "column_mapping = {df.columns[0]: 'AreaName'}\n",
    "df = df.rename(columns=column_mapping)\n",
    "\n",
    "dfengland = dataframes['total-election-turnout-england']\n",
    "column_mapping = {dfengland.columns[0]: 'AreaName'}\n",
    "dfengland = dfengland.rename(columns=column_mapping)\n",
    "dfengland = dfengland.iloc[0,:4]\n",
    "\n",
    "dfwards = dataframes['total-election-turnout-lambethwards']\n",
    "dfwards = dfwards.iloc[:,1:4]\n",
    "dfwards['Ballot box turnout'] = dfwards.iloc[:,2].astype(int)/ dfwards.iloc[:,1].astype(int)\n",
    "column_mapping = {dfwards.columns[0]: 'AreaName'}\n",
    "dfwards = dfwards.rename(columns=column_mapping)\n",
    "\n",
    "election_df = pd.concat([df, dfwards], ignore_index=True)\n",
    "election_df = election_df.append(dfengland, ignore_index=True)\n",
    "election_df['Time period'] = 2022\n",
    "column_mapping = {election_df.columns[2] :'Ballot papers at the count',\n",
    "                  election_df.columns[3]: 'Ballot box turnout'}\n",
    "election_df = election_df.rename(columns=column_mapping)\n",
    "\n",
    "# Combine both years ---------------------------------------------\n",
    "election_df = pd.concat([election_df, election_df2018], ignore_index=True)\n",
    "replace_dict = {'London Borough of Lambeth': 'Lambeth', 'Total London': 'London', 'Total':'England',\n",
    "               'Total London Boroughs':'London'}\n",
    "election_df['AreaName'] = election_df['AreaName'].replace(replace_dict)\n",
    "\n",
    "election_df['Ballot box turnout'] = election_df['Ballot box turnout'].apply(lambda x: round(x * 100, 1))\n",
    "\n",
    "converttojson(election_df, 'election2018-22')\n",
    "election_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "id": "84c8902e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 'weekly-earnings-by-sex' saved as JSON file: Clean Data/weekly-earnings-by-sex.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AreaName</th>\n",
       "      <th>Time period</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lambeth</td>\n",
       "      <td>2022</td>\n",
       "      <td>Male Full Time Workers</td>\n",
       "      <td>1019.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>2022</td>\n",
       "      <td>Male Full Time Workers</td>\n",
       "      <td>824.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>London</td>\n",
       "      <td>2022</td>\n",
       "      <td>Male Full Time Workers</td>\n",
       "      <td>1021.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lambeth</td>\n",
       "      <td>2023</td>\n",
       "      <td>Male Full Time Workers</td>\n",
       "      <td>1166.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>England</td>\n",
       "      <td>2023</td>\n",
       "      <td>Male Full Time Workers</td>\n",
       "      <td>869.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>London</td>\n",
       "      <td>2023</td>\n",
       "      <td>Male Full Time Workers</td>\n",
       "      <td>1065.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lambeth</td>\n",
       "      <td>2022</td>\n",
       "      <td>Female Full Time Workers</td>\n",
       "      <td>890.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>England</td>\n",
       "      <td>2022</td>\n",
       "      <td>Female Full Time Workers</td>\n",
       "      <td>686.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>London</td>\n",
       "      <td>2022</td>\n",
       "      <td>Female Full Time Workers</td>\n",
       "      <td>833.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lambeth</td>\n",
       "      <td>2023</td>\n",
       "      <td>Female Full Time Workers</td>\n",
       "      <td>924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>England</td>\n",
       "      <td>2023</td>\n",
       "      <td>Female Full Time Workers</td>\n",
       "      <td>729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>London</td>\n",
       "      <td>2023</td>\n",
       "      <td>Female Full Time Workers</td>\n",
       "      <td>886.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Lambeth</td>\n",
       "      <td>2022</td>\n",
       "      <td>Full Time Workers</td>\n",
       "      <td>958.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>England</td>\n",
       "      <td>2022</td>\n",
       "      <td>Full Time Workers</td>\n",
       "      <td>768.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>London</td>\n",
       "      <td>2022</td>\n",
       "      <td>Full Time Workers</td>\n",
       "      <td>939.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Lambeth</td>\n",
       "      <td>2023</td>\n",
       "      <td>Full Time Workers</td>\n",
       "      <td>1064.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>England</td>\n",
       "      <td>2023</td>\n",
       "      <td>Full Time Workers</td>\n",
       "      <td>812.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>London</td>\n",
       "      <td>2023</td>\n",
       "      <td>Full Time Workers</td>\n",
       "      <td>985.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AreaName  Time period                       Sex   Value\n",
       "0   Lambeth         2022    Male Full Time Workers  1019.3\n",
       "1   England         2022    Male Full Time Workers   824.5\n",
       "2    London         2022    Male Full Time Workers  1021.6\n",
       "3   Lambeth         2023    Male Full Time Workers  1166.1\n",
       "4   England         2023    Male Full Time Workers   869.7\n",
       "5    London         2023    Male Full Time Workers  1065.6\n",
       "6   Lambeth         2022  Female Full Time Workers   890.1\n",
       "7   England         2022  Female Full Time Workers   686.4\n",
       "8    London         2022  Female Full Time Workers   833.2\n",
       "9   Lambeth         2023  Female Full Time Workers     924\n",
       "10  England         2023  Female Full Time Workers     729\n",
       "11   London         2023  Female Full Time Workers   886.5\n",
       "12  Lambeth         2022         Full Time Workers   958.6\n",
       "13  England         2022         Full Time Workers   768.9\n",
       "14   London         2022         Full Time Workers   939.1\n",
       "15  Lambeth         2023         Full Time Workers  1064.2\n",
       "16  England         2023         Full Time Workers   812.4\n",
       "17   London         2023         Full Time Workers   985.6"
      ]
     },
     "execution_count": 714,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weekly earnings by sex ------------------------------------------------------------------\n",
    "lydf= lydataframes['lastyearweekly-earnings-by-sex']\n",
    "lydf.iloc[:,0] = lydf.iloc[:,0].str.split(':').str[-1]\n",
    "lydf = lydf.iloc[1:,[0,1,3,5]]\n",
    "lydf['Time period'] = 2022\n",
    "\n",
    "df = dataframes['weekly-earnings-by-sex']\n",
    "df.iloc[:,0] = df.iloc[:,0].str.split(':').str[-1]\n",
    "df = df.iloc[1:,[0,1,3,5]]\n",
    "df['Time period'] = 2023\n",
    "\n",
    "filtered_df = pd.concat([lydf, df], ignore_index=True)\n",
    "column_mapping = {filtered_df.columns[0]: 'AreaName'}\n",
    "filtered_df = filtered_df.rename(columns=column_mapping)\n",
    "\n",
    "melted_df = pd.melt(filtered_df, id_vars=['AreaName', 'Time period'], var_name='Sex', value_name='Value')\n",
    "converttojson(melted_df, 'weekly-earnings-by-sex')\n",
    "melted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "a96b0edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 'internetusers2019-20' saved as JSON file: Clean Data/internetusers2019-20.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AreaName</th>\n",
       "      <th>Time period</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UK</td>\n",
       "      <td>2019</td>\n",
       "      <td>90.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>London</td>\n",
       "      <td>2019</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lambeth</td>\n",
       "      <td>2019</td>\n",
       "      <td>95.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UK</td>\n",
       "      <td>2020</td>\n",
       "      <td>92.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>London</td>\n",
       "      <td>2020</td>\n",
       "      <td>94.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lambeth</td>\n",
       "      <td>2020</td>\n",
       "      <td>94.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  AreaName Time period Value\n",
       "0       UK        2019  90.8\n",
       "1   London        2019    93\n",
       "2  Lambeth        2019  95.2\n",
       "3       UK        2020  92.1\n",
       "4   London        2020  94.9\n",
       "5  Lambeth        2020  94.9"
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# % ppl used Internet in the past 3 months\n",
    "df=dataframes['internet-users']\n",
    "df= df.drop(df.columns[[0,2]], axis=1, inplace=False)\n",
    "df = df.iloc[:,:8]\n",
    "column_mapping = {df.columns[0]: 'AreaName'}\n",
    "df = df.rename(columns=column_mapping)\n",
    "filtered_df = df[df.iloc[:,0].isin(['Lambeth','UK','London'])]\n",
    "filtered_df= filtered_df[['AreaName',2019,2020]]\n",
    "melted_df = pd.melt(filtered_df, id_vars='AreaName', var_name='Time period', value_name='Value')\n",
    "converttojson(melted_df, 'internetusers2019-20')\n",
    "melted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "id": "fb7fbc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 'sexual-orientation' saved as JSON file: Clean Data/sexual-orientation.json\n",
      "DataFrame 'gender-identity' saved as JSON file: Clean Data/gender-identity.json\n",
      "DataFrame 'working-age-population' saved as JSON file: Clean Data/working-age-population.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Population aged 16-64 (2021)</th>\n",
       "      <th>Lambeth (Numbers)</th>\n",
       "      <th>Lambeth (%)</th>\n",
       "      <th>London (%)</th>\n",
       "      <th>England (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All People Aged 16-64</td>\n",
       "      <td>241700</td>\n",
       "      <td>76.1</td>\n",
       "      <td>68.8</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Males Aged 16-64</td>\n",
       "      <td>117200</td>\n",
       "      <td>76.1</td>\n",
       "      <td>68.8</td>\n",
       "      <td>63.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Females Aged 16-64</td>\n",
       "      <td>124500</td>\n",
       "      <td>76.2</td>\n",
       "      <td>68.9</td>\n",
       "      <td>62.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Population aged 16-64 (2021) Lambeth (Numbers) Lambeth (%) London (%)  \\\n",
       "2        All People Aged 16-64            241700        76.1       68.8   \n",
       "3             Males Aged 16-64            117200        76.1       68.8   \n",
       "4           Females Aged 16-64            124500        76.2       68.9   \n",
       "\n",
       "  England (%)  \n",
       "2          63  \n",
       "3        63.3  \n",
       "4        62.6  "
      ]
     },
     "execution_count": 822,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dataframes['sexual-orientation']\n",
    "df_filtered = df[df['Sexual orientation'] != 'Straight or Heterosexual']\n",
    "dataframes['sexual-orientation' ] = df_filtered\n",
    "converttojson(dataframes['sexual-orientation'], 'sexual-orientation')\n",
    "\n",
    "df = dataframes['gender-identity']\n",
    "df_filtered = df[df['Gender identity'] != 'Gender identity the same as sex registered at birth']\n",
    "dataframes['gender-identity'] = df_filtered\n",
    "converttojson(dataframes['gender-identity'], 'gender-identity')\n",
    "\n",
    "df= dataframes['working-age-population']\n",
    "new_columns=[df.columns[0]]\n",
    "for i, col in enumerate(df.columns):\n",
    "        if pd.isna(col):\n",
    "            new_col_name = f\"{df.iloc[0, i]} {df.iloc[1, i]}\"\n",
    "            new_columns.append(new_col_name)\n",
    "        else:\n",
    "            continue\n",
    "df.columns = new_columns\n",
    "df = df[2:]\n",
    "converttojson(df, 'working-age-population')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "id": "f0831af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 'personal-wellbeing2021-23' saved as JSON file: Clean Data/personal-wellbeing2021-23.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AreaName</th>\n",
       "      <th>MeasureOfWellbeing</th>\n",
       "      <th>Time period</th>\n",
       "      <th>Average Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>England</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>Happiness</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>7.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>England</td>\n",
       "      <td>Life satisfaction</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>7.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>England</td>\n",
       "      <td>Worthwhile</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>7.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lambeth</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lambeth</td>\n",
       "      <td>Happiness</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lambeth</td>\n",
       "      <td>Life satisfaction</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>7.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lambeth</td>\n",
       "      <td>Worthwhile</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>7.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>London</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>London</td>\n",
       "      <td>Happiness</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>7.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>London</td>\n",
       "      <td>Life satisfaction</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>7.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>London</td>\n",
       "      <td>Worthwhile</td>\n",
       "      <td>2022-23</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>England</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>2021-22</td>\n",
       "      <td>3.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>England</td>\n",
       "      <td>Happiness</td>\n",
       "      <td>2021-22</td>\n",
       "      <td>7.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>England</td>\n",
       "      <td>Life satisfaction</td>\n",
       "      <td>2021-22</td>\n",
       "      <td>7.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>England</td>\n",
       "      <td>Worthwhile</td>\n",
       "      <td>2021-22</td>\n",
       "      <td>7.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Lambeth</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>2021-22</td>\n",
       "      <td>3.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Lambeth</td>\n",
       "      <td>Happiness</td>\n",
       "      <td>2021-22</td>\n",
       "      <td>6.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Lambeth</td>\n",
       "      <td>Life satisfaction</td>\n",
       "      <td>2021-22</td>\n",
       "      <td>7.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Lambeth</td>\n",
       "      <td>Worthwhile</td>\n",
       "      <td>2021-22</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>London</td>\n",
       "      <td>Anxiety</td>\n",
       "      <td>2021-22</td>\n",
       "      <td>3.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>London</td>\n",
       "      <td>Happiness</td>\n",
       "      <td>2021-22</td>\n",
       "      <td>7.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>London</td>\n",
       "      <td>Life satisfaction</td>\n",
       "      <td>2021-22</td>\n",
       "      <td>7.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>London</td>\n",
       "      <td>Worthwhile</td>\n",
       "      <td>2021-22</td>\n",
       "      <td>7.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AreaName MeasureOfWellbeing Time period Average Value\n",
       "0   England            Anxiety     2022-23          3.24\n",
       "1   England          Happiness     2022-23          7.38\n",
       "2   England  Life satisfaction     2022-23          7.44\n",
       "3   England         Worthwhile     2022-23          7.73\n",
       "4   Lambeth            Anxiety     2022-23          3.45\n",
       "5   Lambeth          Happiness     2022-23           7.5\n",
       "6   Lambeth  Life satisfaction     2022-23          7.63\n",
       "7   Lambeth         Worthwhile     2022-23          7.75\n",
       "8    London            Anxiety     2022-23          3.34\n",
       "9    London          Happiness     2022-23          7.32\n",
       "10   London  Life satisfaction     2022-23          7.35\n",
       "11   London         Worthwhile     2022-23           7.6\n",
       "12  England            Anxiety     2021-22          3.13\n",
       "13  England          Happiness     2021-22          7.45\n",
       "14  England  Life satisfaction     2021-22          7.55\n",
       "15  England         Worthwhile     2021-22          7.78\n",
       "16  Lambeth            Anxiety     2021-22          3.92\n",
       "17  Lambeth          Happiness     2021-22          6.99\n",
       "18  Lambeth  Life satisfaction     2021-22          7.41\n",
       "19  Lambeth         Worthwhile     2021-22           7.6\n",
       "20   London            Anxiety     2021-22          3.28\n",
       "21   London          Happiness     2021-22          7.37\n",
       "22   London  Life satisfaction     2021-22          7.46\n",
       "23   London         Worthwhile     2021-22          7.68"
      ]
     },
     "execution_count": 684,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dataframes['personal-wellbeing']\n",
    "df= df[['Geography','MeasureOfWellbeing', '2022-23', '2021-22']]\n",
    "df = df.rename(columns={df.columns[0]: 'AreaName'})\n",
    "melted_df = pd.melt(df, id_vars=['AreaName', 'MeasureOfWellbeing'], var_name='Time period', value_name='Average Value')\n",
    "converttojson(melted_df, 'personal-wellbeing2021-23')\n",
    "melted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "id": "43ea3bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 'children-in-low-income-households-AHC' saved as JSON file: Clean Data/children-in-low-income-households-AHC.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AreaName</th>\n",
       "      <th>Time period</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lambeth</td>\n",
       "      <td>2020/21</td>\n",
       "      <td>38.787097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>2020/21</td>\n",
       "      <td>30.625002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>London</td>\n",
       "      <td>2020/21</td>\n",
       "      <td>37.239079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lambeth</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>35.512054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>England</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>30.777549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>London</td>\n",
       "      <td>2021/22</td>\n",
       "      <td>32.852283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  AreaName Time period Percentage\n",
       "0  Lambeth     2020/21  38.787097\n",
       "1  England     2020/21  30.625002\n",
       "2   London     2020/21  37.239079\n",
       "3  Lambeth     2021/22  35.512054\n",
       "4  England     2021/22  30.777549\n",
       "5   London     2021/22  32.852283"
      ]
     },
     "execution_count": 685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambeth = dataframes['children-in-low-income-households-AHC-Lambeth'].iloc[:, [1] + list(range(11, 19))]\n",
    "london = dataframes['children-in-low-income-households-AHC-London'].iloc[:, [0] + list(range(9, 17))]\n",
    "df = pd.concat([lambeth, london], ignore_index=True)\n",
    "df = df.rename(columns={df.columns[0]: 'AreaName'})\n",
    "df.iloc[:,0] = df.iloc[:,0].str.strip()\n",
    "filtered_df = df[df.iloc[:,0].isin(['Lambeth','England','London'])]\n",
    "filtered_df= filtered_df[['AreaName','2020/21','2021/22']]\n",
    "filtered_df.iloc[:, 1:3] = filtered_df.iloc[:, 1:3] * 100\n",
    "melted_df = pd.melt(filtered_df, id_vars=['AreaName'], var_name='Time period', value_name='Percentage')\n",
    "\n",
    "converttojson(melted_df, 'children-in-low-income-households-AHC')\n",
    "melted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1115,
   "id": "f4696ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 'survey_wellbeing_cost' saved as JSON file: Clean Data/survey_wellbeing_cost.json\n",
      "DataFrame 'lastyearsurvey_wellbeing_cost' saved as JSON file: Clean Data/lastyearsurvey_wellbeing_cost.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\2998876437.py:15: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  surv_sat_f_cost['Response'] = surv_sat_f_cost['Response'].str.replace(r'\\[.*\\]', '')\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\2998876437.py:36: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  lysurv_sat_f_cost['Response'] = lysurv_sat_f_cost['Response'].str.replace(r'\\[.*\\]', '')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Response</th>\n",
       "      <th>Percentage of respondents</th>\n",
       "      <th>Question</th>\n",
       "      <th>Time period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Got worse</td>\n",
       "      <td>49.3</td>\n",
       "      <td>Compared with this time last year, do you thin...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stayed the same</td>\n",
       "      <td>28.7</td>\n",
       "      <td>Compared with this time last year, do you thin...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Improved</td>\n",
       "      <td>19.9</td>\n",
       "      <td>Compared with this time last year, do you thin...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very difficult</td>\n",
       "      <td>6.8</td>\n",
       "      <td>Over the next year, how easy or difficult do y...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Difficult</td>\n",
       "      <td>9.6</td>\n",
       "      <td>Over the next year, how easy or difficult do y...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fairly difficult</td>\n",
       "      <td>10.8</td>\n",
       "      <td>Over the next year, how easy or difficult do y...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fairly easy</td>\n",
       "      <td>31.2</td>\n",
       "      <td>Over the next year, how easy or difficult do y...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Easy</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Over the next year, how easy or difficult do y...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Very easy</td>\n",
       "      <td>17.5</td>\n",
       "      <td>Over the next year, how easy or difficult do y...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Very difficult</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Over the next year, how easy or difficult do y...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Difficult</td>\n",
       "      <td>13.1</td>\n",
       "      <td>Over the next year, how easy or difficult do y...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Fairly difficult</td>\n",
       "      <td>17.7</td>\n",
       "      <td>Over the next year, how easy or difficult do y...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Fairly easy</td>\n",
       "      <td>25.1</td>\n",
       "      <td>Over the next year, how easy or difficult do y...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Easy</td>\n",
       "      <td>13.7</td>\n",
       "      <td>Over the next year, how easy or difficult do y...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Very easy</td>\n",
       "      <td>8.8</td>\n",
       "      <td>Over the next year, how easy or difficult do y...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Very difficult</td>\n",
       "      <td>10.7</td>\n",
       "      <td>Over the next year, how easy or difficult do y...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Difficult</td>\n",
       "      <td>11.4</td>\n",
       "      <td>Over the next year, how easy or difficult do y...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Fairly difficult</td>\n",
       "      <td>17.1</td>\n",
       "      <td>Over the next year, how easy or difficult do y...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Fairly easy</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Over the next year, how easy or difficult do y...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Easy</td>\n",
       "      <td>12.4</td>\n",
       "      <td>Over the next year, how easy or difficult do y...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Very easy</td>\n",
       "      <td>8.3</td>\n",
       "      <td>Over the next year, how easy or difficult do y...</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Response  Percentage of respondents  \\\n",
       "0          Got worse                       49.3   \n",
       "1    Stayed the same                       28.7   \n",
       "2           Improved                       19.9   \n",
       "3     Very difficult                        6.8   \n",
       "4          Difficult                        9.6   \n",
       "5   Fairly difficult                       10.8   \n",
       "6        Fairly easy                       31.2   \n",
       "7               Easy                       20.0   \n",
       "8          Very easy                       17.5   \n",
       "9     Very difficult                       18.0   \n",
       "10         Difficult                       13.1   \n",
       "11  Fairly difficult                       17.7   \n",
       "12       Fairly easy                       25.1   \n",
       "13              Easy                       13.7   \n",
       "14         Very easy                        8.8   \n",
       "15    Very difficult                       10.7   \n",
       "16         Difficult                       11.4   \n",
       "17  Fairly difficult                       17.1   \n",
       "18       Fairly easy                       25.0   \n",
       "19              Easy                       12.4   \n",
       "20         Very easy                        8.3   \n",
       "\n",
       "                                             Question  Time period  \n",
       "0   Compared with this time last year, do you thin...         2022  \n",
       "1   Compared with this time last year, do you thin...         2022  \n",
       "2   Compared with this time last year, do you thin...         2022  \n",
       "3   Over the next year, how easy or difficult do y...         2022  \n",
       "4   Over the next year, how easy or difficult do y...         2022  \n",
       "5   Over the next year, how easy or difficult do y...         2022  \n",
       "6   Over the next year, how easy or difficult do y...         2022  \n",
       "7   Over the next year, how easy or difficult do y...         2022  \n",
       "8   Over the next year, how easy or difficult do y...         2022  \n",
       "9   Over the next year, how easy or difficult do y...         2022  \n",
       "10  Over the next year, how easy or difficult do y...         2022  \n",
       "11  Over the next year, how easy or difficult do y...         2022  \n",
       "12  Over the next year, how easy or difficult do y...         2022  \n",
       "13  Over the next year, how easy or difficult do y...         2022  \n",
       "14  Over the next year, how easy or difficult do y...         2022  \n",
       "15  Over the next year, how easy or difficult do y...         2022  \n",
       "16  Over the next year, how easy or difficult do y...         2022  \n",
       "17  Over the next year, how easy or difficult do y...         2022  \n",
       "18  Over the next year, how easy or difficult do y...         2022  \n",
       "19  Over the next year, how easy or difficult do y...         2022  \n",
       "20  Over the next year, how easy or difficult do y...         2022  "
      ]
     },
     "execution_count": 1115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cost of Living Resident survey ----------------------------------------------------------\n",
    "q032 = dataframes['resident-survey-results---financial']\n",
    "q4ay22_1 = dataframes['resident-survey-results---payforfood']\n",
    "q4ay22_2 = dataframes['resident-survey-results---payforenergy']\n",
    "q4ay22_3 = dataframes['resident-survey-results---payforrent']\n",
    "\n",
    "# Join all DataFrames\n",
    "surv_sat_f_cost = pd.concat([q032, q4ay22_1, q4ay22_2, q4ay22_3], ignore_index=True)\n",
    "\n",
    "# Add a 'Year' column with value 2023\n",
    "surv_sat_f_cost['Time period'] = 2023\n",
    "surv_sat_f_cost.drop(surv_sat_f_cost.columns[2], axis=1, inplace=True)\n",
    "\n",
    "# Remove anything between square brackets in Responses\n",
    "surv_sat_f_cost['Response'] = surv_sat_f_cost['Response'].str.replace(r'\\[.*\\]', '')\n",
    "\n",
    "# Make 'Response' an ordered categorical column with levels in the order of appearance\n",
    "surv_sat_f_cost['Response'] = pd.Categorical(surv_sat_f_cost['Response'], categories=surv_sat_f_cost['Response'].unique(), ordered=True)\n",
    "converttojson(surv_sat_f_cost,'survey_wellbeing_cost')\n",
    "surv_sat_f_cost\n",
    "\n",
    "# Last Year Cost of Living Resident survey ----------------------------------------------------------\n",
    "q032 = lydataframes['lastyearresident-survey-results---financial']\n",
    "q4ay22_1 = lydataframes['lastyearresident-survey-results---payforfood']\n",
    "q4ay22_2 = lydataframes['lastyearresident-survey-results---payforenergy']\n",
    "q4ay22_3 = lydataframes['lastyearresident-survey-results---payforrent']\n",
    "\n",
    "# Join all DataFrames\n",
    "lysurv_sat_f_cost = pd.concat([q032, q4ay22_1, q4ay22_2, q4ay22_3], ignore_index=True)\n",
    "\n",
    "# Add a 'Year' column with value 2022\n",
    "lysurv_sat_f_cost['Time period'] = 2022\n",
    "lysurv_sat_f_cost\n",
    "\n",
    "# Remove anything between square brackets in Responses\n",
    "lysurv_sat_f_cost['Response'] = lysurv_sat_f_cost['Response'].str.replace(r'\\[.*\\]', '')\n",
    "\n",
    "# Make 'Response' an ordered categorical column with levels in the order of appearance\n",
    "lysurv_sat_f_cost['Response'] = pd.Categorical(lysurv_sat_f_cost['Response'], categories=lysurv_sat_f_cost['Response'].unique(), ordered=True)\n",
    "converttojson(lysurv_sat_f_cost,'lastyearsurvey_wellbeing_cost')\n",
    "lysurv_sat_f_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "id": "64ef6bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 'survey_wellbeing_health' saved as JSON file: Clean Data/survey_wellbeing_health.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\1093869634.py:16: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  surv_sat_f_health['Response'] = surv_sat_f_health['Response'].str.replace(r'\\[.*\\]', '')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Response</th>\n",
       "      <th>Percentage of respondents</th>\n",
       "      <th>Brixton Acre Lane</th>\n",
       "      <th>Brixton North</th>\n",
       "      <th>Brixton Rush Common</th>\n",
       "      <th>Brixton Windrush</th>\n",
       "      <th>Clapham Common &amp; Abbeville</th>\n",
       "      <th>Clapham East</th>\n",
       "      <th>Clapham Park</th>\n",
       "      <th>Clapham Town</th>\n",
       "      <th>...</th>\n",
       "      <th>Streatham Common &amp; Vale</th>\n",
       "      <th>Streatham Hill East</th>\n",
       "      <th>Streatham Hill West &amp; Thornton</th>\n",
       "      <th>Streatham St Leonard's</th>\n",
       "      <th>Streatham Wells</th>\n",
       "      <th>Vauxhall</th>\n",
       "      <th>Waterloo &amp; South Bank</th>\n",
       "      <th>West Dulwich</th>\n",
       "      <th>Question</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0 - Not at all worthwhile</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Overall, to what extent do you feel the things...</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Overall, to what extent do you feel the things...</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Overall, to what extent do you feel the things...</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>Overall, to what extent do you feel the things...</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Overall, to what extent do you feel the things...</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>6.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.2</td>\n",
       "      <td>9.2</td>\n",
       "      <td>9.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>9.7</td>\n",
       "      <td>4.3</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>8.5</td>\n",
       "      <td>7.4</td>\n",
       "      <td>11.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>9.7</td>\n",
       "      <td>11.6</td>\n",
       "      <td>Overall, to what extent do you feel the things...</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>10.7</td>\n",
       "      <td>12.6</td>\n",
       "      <td>11.9</td>\n",
       "      <td>4.6</td>\n",
       "      <td>7.4</td>\n",
       "      <td>13.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5.7</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>9.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>8.1</td>\n",
       "      <td>11.1</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Overall, to what extent do you feel the things...</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>22.5</td>\n",
       "      <td>6.6</td>\n",
       "      <td>20.3</td>\n",
       "      <td>23.9</td>\n",
       "      <td>10.5</td>\n",
       "      <td>14.2</td>\n",
       "      <td>22.5</td>\n",
       "      <td>...</td>\n",
       "      <td>9.3</td>\n",
       "      <td>16.6</td>\n",
       "      <td>19.3</td>\n",
       "      <td>15.4</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.8</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>Overall, to what extent do you feel the things...</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>23.3</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>25.8</td>\n",
       "      <td>34.3</td>\n",
       "      <td>26.7</td>\n",
       "      <td>20.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>...</td>\n",
       "      <td>22.5</td>\n",
       "      <td>18.8</td>\n",
       "      <td>31.5</td>\n",
       "      <td>24.6</td>\n",
       "      <td>17.5</td>\n",
       "      <td>17.6</td>\n",
       "      <td>13.8</td>\n",
       "      <td>30.4</td>\n",
       "      <td>Overall, to what extent do you feel the things...</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>11.1</td>\n",
       "      <td>12.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.6</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.1</td>\n",
       "      <td>13.3</td>\n",
       "      <td>11.4</td>\n",
       "      <td>11.7</td>\n",
       "      <td>...</td>\n",
       "      <td>18.9</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.8</td>\n",
       "      <td>11.3</td>\n",
       "      <td>14.8</td>\n",
       "      <td>22.7</td>\n",
       "      <td>7.5</td>\n",
       "      <td>11.6</td>\n",
       "      <td>Overall, to what extent do you feel the things...</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10 - Completely worthwhile</td>\n",
       "      <td>26.3</td>\n",
       "      <td>23.3</td>\n",
       "      <td>28.5</td>\n",
       "      <td>18.7</td>\n",
       "      <td>22.7</td>\n",
       "      <td>24.5</td>\n",
       "      <td>31.7</td>\n",
       "      <td>23.8</td>\n",
       "      <td>31.8</td>\n",
       "      <td>...</td>\n",
       "      <td>25.6</td>\n",
       "      <td>25.7</td>\n",
       "      <td>17.1</td>\n",
       "      <td>27.1</td>\n",
       "      <td>26.3</td>\n",
       "      <td>29.7</td>\n",
       "      <td>42.1</td>\n",
       "      <td>20.9</td>\n",
       "      <td>Overall, to what extent do you feel the things...</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0 - Not at all anxious</td>\n",
       "      <td>21.1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>15.8</td>\n",
       "      <td>25.1</td>\n",
       "      <td>18.4</td>\n",
       "      <td>25.8</td>\n",
       "      <td>21.6</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>33.9</td>\n",
       "      <td>11.5</td>\n",
       "      <td>28.2</td>\n",
       "      <td>26.5</td>\n",
       "      <td>18.9</td>\n",
       "      <td>23.9</td>\n",
       "      <td>16.7</td>\n",
       "      <td>20.0</td>\n",
       "      <td>How anxious did you feel yesterday?</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.6</td>\n",
       "      <td>11.6</td>\n",
       "      <td>12.5</td>\n",
       "      <td>13.6</td>\n",
       "      <td>7.1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>5.2</td>\n",
       "      <td>7.7</td>\n",
       "      <td>10.2</td>\n",
       "      <td>How anxious did you feel yesterday?</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>8.7</td>\n",
       "      <td>9.4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.1</td>\n",
       "      <td>16.5</td>\n",
       "      <td>10.7</td>\n",
       "      <td>8.3</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6.6</td>\n",
       "      <td>...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.9</td>\n",
       "      <td>8.2</td>\n",
       "      <td>18.9</td>\n",
       "      <td>20.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>How anxious did you feel yesterday?</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>8.4</td>\n",
       "      <td>6.6</td>\n",
       "      <td>8.6</td>\n",
       "      <td>11.9</td>\n",
       "      <td>14.6</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>9.1</td>\n",
       "      <td>7.1</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>5.5</td>\n",
       "      <td>9.3</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>How anxious did you feel yesterday?</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>5.9</td>\n",
       "      <td>9.3</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5.2</td>\n",
       "      <td>7.6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>9.3</td>\n",
       "      <td>...</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>14.1</td>\n",
       "      <td>How anxious did you feel yesterday?</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>11.4</td>\n",
       "      <td>11.2</td>\n",
       "      <td>17.2</td>\n",
       "      <td>12.1</td>\n",
       "      <td>5.7</td>\n",
       "      <td>14.8</td>\n",
       "      <td>7.9</td>\n",
       "      <td>8.9</td>\n",
       "      <td>12.7</td>\n",
       "      <td>...</td>\n",
       "      <td>10.1</td>\n",
       "      <td>8.8</td>\n",
       "      <td>12.5</td>\n",
       "      <td>4.7</td>\n",
       "      <td>6.2</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>7.8</td>\n",
       "      <td>How anxious did you feel yesterday?</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6</td>\n",
       "      <td>8.3</td>\n",
       "      <td>10.9</td>\n",
       "      <td>10.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>7.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>7.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>7.8</td>\n",
       "      <td>...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>8.4</td>\n",
       "      <td>11.7</td>\n",
       "      <td>6.6</td>\n",
       "      <td>8.2</td>\n",
       "      <td>10.6</td>\n",
       "      <td>10.6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>How anxious did you feel yesterday?</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7</td>\n",
       "      <td>7.8</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>7.8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>...</td>\n",
       "      <td>8.4</td>\n",
       "      <td>16.3</td>\n",
       "      <td>3.1</td>\n",
       "      <td>7.1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>7.3</td>\n",
       "      <td>How anxious did you feel yesterday?</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8</td>\n",
       "      <td>9.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>12.9</td>\n",
       "      <td>9.3</td>\n",
       "      <td>16.6</td>\n",
       "      <td>6.8</td>\n",
       "      <td>8.5</td>\n",
       "      <td>8.9</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.9</td>\n",
       "      <td>11.9</td>\n",
       "      <td>12.9</td>\n",
       "      <td>8.4</td>\n",
       "      <td>9.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>How anxious did you feel yesterday?</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>How anxious did you feel yesterday?</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10 - Completely anxious</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.9</td>\n",
       "      <td>8.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>5.8</td>\n",
       "      <td>...</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>9.9</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>How anxious did you feel yesterday?</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Response  Percentage of respondents  Brixton Acre Lane  \\\n",
       "0    0 - Not at all worthwhile                        1.0                0.0   \n",
       "1                            1                        0.1                0.0   \n",
       "2                            2                        1.1                0.8   \n",
       "3                            3                        1.2                1.7   \n",
       "4                            4                        1.3                3.4   \n",
       "5                            5                        6.2                4.8   \n",
       "6                            6                        6.9               10.7   \n",
       "7                            7                       16.0               14.4   \n",
       "8                            8                       23.3               25.0   \n",
       "9                            9                       11.1               12.2   \n",
       "10  10 - Completely worthwhile                       26.3               23.3   \n",
       "11    0 - Not at all anxious                         21.1               18.0   \n",
       "12                         1                          6.1                8.0   \n",
       "13                         2                          8.7                9.4   \n",
       "14                         3                          8.4                6.6   \n",
       "15                         4                          5.9                9.3   \n",
       "16                         5                         11.4               11.2   \n",
       "17                         6                          8.3               10.9   \n",
       "18                         7                          7.8               11.0   \n",
       "19                         8                          9.2                6.0   \n",
       "20                         9                          2.5                2.6   \n",
       "21   10 - Completely anxious                          6.0                3.4   \n",
       "\n",
       "    Brixton North  Brixton Rush Common  Brixton Windrush  \\\n",
       "0             0.0                  4.0               0.0   \n",
       "1             0.9                  0.0               0.0   \n",
       "2             0.0                  3.3               0.0   \n",
       "3             3.2                  0.0               0.0   \n",
       "4             1.3                  5.5               0.0   \n",
       "5             4.2                  9.2               9.3   \n",
       "6            12.6                 11.9               4.6   \n",
       "7            22.5                  6.6              20.3   \n",
       "8            20.1                 25.8              34.3   \n",
       "9             2.5                  7.6               6.5   \n",
       "10           28.5                 18.7              22.7   \n",
       "11           23.2                 15.8              25.1   \n",
       "12            2.5                  6.7               3.6   \n",
       "13            2.5                  7.1              16.5   \n",
       "14            8.6                 11.9              14.6   \n",
       "15            9.8                  5.2               7.6   \n",
       "16           17.2                 12.1               5.7   \n",
       "17           10.2                  4.9               7.1   \n",
       "18            9.2                  3.4               4.7   \n",
       "19            5.6                 12.9               9.3   \n",
       "20            4.1                  6.8               0.0   \n",
       "21            4.9                  8.7               2.9   \n",
       "\n",
       "    Clapham Common & Abbeville  Clapham East  Clapham Park  Clapham Town  ...  \\\n",
       "0                          2.7           0.0           0.0           1.3  ...   \n",
       "1                          0.0           0.0           0.0           0.0  ...   \n",
       "2                          0.0           0.0           3.6           0.0  ...   \n",
       "3                          0.0           1.3           0.0           0.0  ...   \n",
       "4                          0.0           2.3           4.1           0.0  ...   \n",
       "5                          3.3           2.4           9.7           4.3  ...   \n",
       "6                          7.4          13.4           5.4           5.7  ...   \n",
       "7                         23.9          10.5          14.2          22.5  ...   \n",
       "8                         26.7          20.4          20.0          16.6  ...   \n",
       "9                          6.1          13.3          11.4          11.7  ...   \n",
       "10                        24.5          31.7          23.8          31.8  ...   \n",
       "11                        18.4          25.8          21.6          16.0  ...   \n",
       "12                        11.6          12.5          13.6           7.1  ...   \n",
       "13                        10.7           8.3           6.4           6.6  ...   \n",
       "14                         5.5           4.4           9.1           7.1  ...   \n",
       "15                         6.0           2.3           2.9           9.3  ...   \n",
       "16                        14.8           7.9           8.9          12.7  ...   \n",
       "17                         3.3           7.1           5.5           7.8  ...   \n",
       "18                         3.3           7.8           8.0          11.8  ...   \n",
       "19                        16.6           6.8           8.5           8.9  ...   \n",
       "20                         0.7           4.6           1.9           0.4  ...   \n",
       "21                         8.3           8.0           7.8           5.8  ...   \n",
       "\n",
       "    Streatham Common & Vale  Streatham Hill East  \\\n",
       "0                       1.6                  0.0   \n",
       "1                       0.5                  0.5   \n",
       "2                       0.9                  3.0   \n",
       "3                       3.5                  0.0   \n",
       "4                       0.9                  0.0   \n",
       "5                       6.0                  3.9   \n",
       "6                       4.4                  9.9   \n",
       "7                       9.3                 16.6   \n",
       "8                      22.5                 18.8   \n",
       "9                      18.9                  9.5   \n",
       "10                     25.6                 25.7   \n",
       "11                     33.9                 11.5   \n",
       "12                      4.9                  3.0   \n",
       "13                      3.9                  4.5   \n",
       "14                      6.0                 12.4   \n",
       "15                      2.2                  4.2   \n",
       "16                     10.1                  8.8   \n",
       "17                      8.5                  8.4   \n",
       "18                      8.4                 16.3   \n",
       "19                      8.0                 15.9   \n",
       "20                      5.5                  1.3   \n",
       "21                      3.6                  4.3   \n",
       "\n",
       "    Streatham Hill West & Thornton  Streatham St Leonard's  Streatham Wells  \\\n",
       "0                              1.6                     1.0              3.0   \n",
       "1                              0.0                     0.0              0.0   \n",
       "2                              3.9                     0.0              0.0   \n",
       "3                              2.1                     2.6              0.0   \n",
       "4                              2.8                     0.0              0.5   \n",
       "5                              8.5                     7.4             11.2   \n",
       "6                              1.0                     8.4              8.1   \n",
       "7                             19.3                    15.4             13.0   \n",
       "8                             31.5                    24.6             17.5   \n",
       "9                             10.8                    11.3             14.8   \n",
       "10                            17.1                    27.1             26.3   \n",
       "11                            28.2                    26.5             18.9   \n",
       "12                             4.9                     4.7              1.4   \n",
       "13                             5.9                     8.2             18.9   \n",
       "14                             5.5                     9.3              4.9   \n",
       "15                             9.3                     1.9              6.0   \n",
       "16                            12.5                     4.7              6.2   \n",
       "17                            11.7                     6.6              8.2   \n",
       "18                             3.1                     7.1              7.9   \n",
       "19                            11.9                    12.9              8.4   \n",
       "20                             2.6                     3.2              3.1   \n",
       "21                             4.6                     9.9             11.0   \n",
       "\n",
       "    Vauxhall  Waterloo & South Bank  West Dulwich  \\\n",
       "0        0.0                    0.0           0.0   \n",
       "1        0.0                    0.0           0.0   \n",
       "2        1.0                    0.0           0.0   \n",
       "3        0.0                    0.8           3.3   \n",
       "4        0.0                    0.0           0.0   \n",
       "5        5.7                    9.7          11.6   \n",
       "6       11.1                    4.6           0.5   \n",
       "7        9.8                   13.0          16.2   \n",
       "8       17.6                   13.8          30.4   \n",
       "9       22.7                    7.5          11.6   \n",
       "10      29.7                   42.1          20.9   \n",
       "11      23.9                   16.7          20.0   \n",
       "12       5.2                    7.7          10.2   \n",
       "13      20.4                   10.0           9.2   \n",
       "14       1.0                   10.5           4.2   \n",
       "15       5.1                    3.8          14.1   \n",
       "16      14.0                    8.1           7.8   \n",
       "17      10.6                   10.6           6.0   \n",
       "18       0.0                    8.5           7.3   \n",
       "19       9.8                   15.0          13.6   \n",
       "20       0.0                    0.0           1.3   \n",
       "21       7.5                    9.2           2.8   \n",
       "\n",
       "                                             Question  Year  \n",
       "0   Overall, to what extent do you feel the things...  2023  \n",
       "1   Overall, to what extent do you feel the things...  2023  \n",
       "2   Overall, to what extent do you feel the things...  2023  \n",
       "3   Overall, to what extent do you feel the things...  2023  \n",
       "4   Overall, to what extent do you feel the things...  2023  \n",
       "5   Overall, to what extent do you feel the things...  2023  \n",
       "6   Overall, to what extent do you feel the things...  2023  \n",
       "7   Overall, to what extent do you feel the things...  2023  \n",
       "8   Overall, to what extent do you feel the things...  2023  \n",
       "9   Overall, to what extent do you feel the things...  2023  \n",
       "10  Overall, to what extent do you feel the things...  2023  \n",
       "11                How anxious did you feel yesterday?  2023  \n",
       "12                How anxious did you feel yesterday?  2023  \n",
       "13                How anxious did you feel yesterday?  2023  \n",
       "14                How anxious did you feel yesterday?  2023  \n",
       "15                How anxious did you feel yesterday?  2023  \n",
       "16                How anxious did you feel yesterday?  2023  \n",
       "17                How anxious did you feel yesterday?  2023  \n",
       "18                How anxious did you feel yesterday?  2023  \n",
       "19                How anxious did you feel yesterday?  2023  \n",
       "20                How anxious did you feel yesterday?  2023  \n",
       "21                How anxious did you feel yesterday?  2023  \n",
       "\n",
       "[22 rows x 29 columns]"
      ]
     },
     "execution_count": 695,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Health Wellbeing Resident survey ----------------------------------------------------------\n",
    "q029 = dataframes['wellbeing---resident-survey-worthwhile']\n",
    "q030 = dataframes['wellbeing---resident-survey-anxiety']\n",
    "\n",
    "# Add a space to each row of the Response column in q030\n",
    "q030['Response'] = q030['Response'] + \" \"\n",
    "\n",
    "# Join all DataFrames\n",
    "surv_sat_f_health = pd.concat([q029, q030], ignore_index=True)\n",
    "surv_sat_f_health.drop(surv_sat_f_health.columns[2], axis=1, inplace=True)\n",
    "\n",
    "# Add a 'Year' column with value 2023\n",
    "surv_sat_f_health['Time period'] = 2023\n",
    "\n",
    "# Remove anything between square brackets in Responses\n",
    "surv_sat_f_health['Response'] = surv_sat_f_health['Response'].str.replace(r'\\[.*\\]', '')\n",
    "\n",
    "# Make 'Response' an ordered categorical column with levels in the order of appearance\n",
    "surv_sat_f_health['Response'] = pd.Categorical(surv_sat_f_health['Response'], categories=surv_sat_f_health['Response'].unique(), ordered=True)\n",
    "converttojson(surv_sat_f_health,'survey_wellbeing_health')\n",
    "surv_sat_f_health\n",
    "\n",
    "# Last year Health Wellbeing Resident survey ----------------------------------------------------------\n",
    "q029 = lydataframes['lastyearwellbeing---resident-survey-worthwhile']\n",
    "q030 = lydataframes['lastyearwellbeing---resident-survey-anxiety']\n",
    "\n",
    "# Add a space to each row of the Response column in q030\n",
    "q030['Response'] = q030['Response'] + \" \"\n",
    "\n",
    "# Join all DataFrames\n",
    "lastyearsurv_sat_f_health = pd.concat([q029, q030], ignore_index=True)\n",
    "\n",
    "# Add a 'Year' column with value 2022\n",
    "lastyearsurv_sat_f_health['Time period'] = 2022\n",
    "\n",
    "# Remove anything between square brackets in Responses\n",
    "lastyearsurv_sat_f_health['Response'] = lastyearsurv_sat_f_health['Response'].str.replace(r'\\[.*\\]', '')\n",
    "\n",
    "# Make 'Response' an ordered categorical column with levels in the order of appearance\n",
    "lastyearsurv_sat_f_health['Response'] = pd.Categorical(lastyearsurv_sat_f_health['Response'], categories=lastyearsurv_sat_f_health['Response'].unique(), ordered=True)\n",
    "\n",
    "converttojson(lastyearsurv_sat_f_health,'lastyearsurvey_wellbeing_health')\n",
    "lastyearsurv_sat_f_health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1124,
   "id": "3b0cd350",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\2361817921.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  q07['Response'] = q07['Response'] + \" \"\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\2361817921.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  q07['Response'] = q07['Response'].str.replace(\"Clean streets\", \"Clean streets \", regex=False)\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\2361817921.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  q07['Response'] = q07['Response'].str.replace(\"The level of crime\", \"The level of crime \", regex=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 'survey_data-overallandcouncil' saved as JSON file: Clean Data/survey_data-overallandcouncil.json\n",
      "DataFrame 'survey_data-improvingthearea' saved as JSON file: Clean Data/survey_data-improvingthearea.json\n",
      "DataFrame 'lastyearsurvey_data-overallandcouncil' saved as JSON file: Clean Data/lastyearsurvey_data-overallandcouncil.json\n",
      "DataFrame 'lastyearsurvey_data-improvingthearea' saved as JSON file: Clean Data/lastyearsurvey_data-improvingthearea.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\2361817921.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  q07['Response'] = q07['Response'] + \" \"\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\2361817921.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  q07['Response'] = q07['Response'].str.replace(\"Clean streets\", \"Clean streets \", regex=False)\n",
      "C:\\Users\\JKim\\AppData\\Local\\Temp\\ipykernel_19392\\2361817921.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  q07['Response'] = q07['Response'].str.replace(\"The level of crime\", \"The level of crime \", regex=False)\n"
     ]
    }
   ],
   "source": [
    "#Current year Council and Overall / Improving the Area survey results\n",
    "q01 = dataframes['resident-survey-results---council-satisfaction-of-life']\n",
    "q02 = dataframes['resident-survey-results---council-runs-things']\n",
    "q03 = dataframes['resident-survey-results---council-value']\n",
    "q04 = dataframes['resident-survey-results---council-informed']\n",
    "q05 = dataframes['resident-survey-results---council-influence-decisions']\n",
    "q06 = dataframes['resident-survey-results---improving-the-area'].iloc[:10]\n",
    "q07 = dataframes['resident-survey-results---top3improve'].iloc[:10]\n",
    "\n",
    "# Assuming q07 is a pandas DataFrame and Response is one of its columns\n",
    "q07['Response'] = q07['Response'] + \" \"\n",
    "\n",
    "q07['Response'] = q07['Response'].str.replace(\"Clean streets\", \"Clean streets \", regex=False)\n",
    "q07['Response'] = q07['Response'].str.replace(\"The level of crime\", \"The level of crime \", regex=False)\n",
    "surv_sat_f_general = pd.concat([q01, q02, q03, q04, q05], ignore_index=True)\n",
    "surv_sat_f_general.drop(surv_sat_f_general.columns[2], axis=1, inplace=True)\n",
    "surv_sat_f_general['Year']=2023\n",
    "\n",
    "surv_sat_f_general['Response'] = pd.Categorical(surv_sat_f_general['Response'], categories=surv_sat_f_general['Response'].unique(), ordered=True)\n",
    "converttojson(surv_sat_f_general, 'survey_data-overallandcouncil')\n",
    "\n",
    "surv_sat_f_general = pd.concat([q06, q07], ignore_index=True)\n",
    "surv_sat_f_general.drop(surv_sat_f_general.columns[2], axis=1, inplace=True)\n",
    "surv_sat_f_general['Year']=2023\n",
    "\n",
    "surv_sat_f_general['Response'] = pd.Categorical(surv_sat_f_general['Response'], categories=surv_sat_f_general['Response'].unique(), ordered=True)\n",
    "converttojson(surv_sat_f_general, 'survey_data-improvingthearea')\n",
    "\n",
    "#Last year Community - Council and Overall / Improving the Area survey results -------------------\n",
    "q01 = lydataframes['lastyearresident-survey-results---council-satisfaction-of-life']\n",
    "q02 = lydataframes['lastyearresident-survey-results---council-runs-things']\n",
    "q03 = lydataframes['lastyearresident-survey-results---council-value']\n",
    "q04 = lydataframes['lastyearresident-survey-results---council-informed']\n",
    "q05 = lydataframes['lastyearresident-survey-results---council-influence-decisions']\n",
    "q06 = lydataframes['lastyearresident-survey-results---improving-the-area'].iloc[:10]\n",
    "q07 = lydataframes['lastyearresident-survey-results---top3improve'].iloc[:10]\n",
    "\n",
    "# Assuming q07 is a pandas DataFrame and Response is one of its columns\n",
    "q07['Response'] = q07['Response'] + \" \"\n",
    "\n",
    "q07['Response'] = q07['Response'].str.replace(\"Clean streets\", \"Clean streets \", regex=False)\n",
    "q07['Response'] = q07['Response'].str.replace(\"The level of crime\", \"The level of crime \", regex=False)\n",
    "surv_sat_f_general = pd.concat([q01, q02, q03, q04, q05], ignore_index=True)\n",
    "surv_sat_f_general['Year']=2022\n",
    "surv_sat_f_general['Response'] = pd.Categorical(surv_sat_f_general['Response'], categories=surv_sat_f_general['Response'].unique(), ordered=True)\n",
    "converttojson(surv_sat_f_general, 'lastyearsurvey_data-overallandcouncil')\n",
    "\n",
    "surv_sat_f_general = pd.concat([q01, q02, q03, q04, q05, q06, q07], ignore_index=True)\n",
    "surv_sat_f_general['Year']=2022\n",
    "surv_sat_f_general['Response'] = pd.Categorical(surv_sat_f_general['Response'], categories=surv_sat_f_general['Response'].unique(), ordered=True)\n",
    "converttojson(surv_sat_f_general, 'lastyearsurvey_data-improvingthearea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "id": "9f6c5c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 'survey_data-localarea' saved as JSON file: Clean Data/survey_data-localarea.json\n",
      "DataFrame 'lastyearsurvey_data-localarea' saved as JSON file: Clean Data/lastyearsurvey_data-localarea.json\n"
     ]
    }
   ],
   "source": [
    "# Current year Local area survey results\n",
    "# Create DataFrames for each question\n",
    "q08 = dataframes['resident-survey-results---local-area-diffbackgrounds'] \n",
    "q091 = dataframes['resident-survey-results---need-help']\n",
    "q092 = dataframes['resident-survey-results---work-together']\n",
    "\n",
    "# Concatenate (join) all dataframes\n",
    "surv_sat_f_local = pd.concat([q08, q091, q092])\n",
    "surv_sat_f_local.drop(surv_sat_f_local.columns[2], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Remove prefix from Question column\n",
    "surv_sat_f_local['Question'] = surv_sat_f_local['Question'].str.replace(\"Please say how strongly you agree or disagree with each of the following statements - \", \"\")\n",
    "\n",
    "# Create an ordered factor for the Response column\n",
    "Response_unique_loc = surv_sat_f_local['Response'].unique()\n",
    "surv_sat_f_local['Response'] = pd.Categorical(surv_sat_f_local['Response'], categories=Response_unique_loc, ordered=True)\n",
    "converttojson(surv_sat_f_local, 'survey_data-localarea')\n",
    "\n",
    "# Last year Local area survey results------------------------------------------------------\n",
    "q08 = lydataframes['lastyearresident-survey-results---local-area-diffbackgrounds'] \n",
    "q091 = lydataframes['lastyearresident-survey-results---need-help']\n",
    "q092 = lydataframes['lastyearresident-survey-results---work-together']\n",
    "\n",
    "# Concatenate (join) all dataframes\n",
    "surv_sat_f_local = pd.concat([q08, q091, q092])\n",
    "\n",
    "# Remove prefix from Question column\n",
    "surv_sat_f_local['Question'] = surv_sat_f_local['Question'].str.replace(\"Please say how strongly you agree or disagree with each of the following statements - \", \"\")\n",
    "\n",
    "# Create an ordered factor for the Response column\n",
    "Response_unique_loc = surv_sat_f_local['Response'].unique()\n",
    "surv_sat_f_local['Response'] = pd.Categorical(surv_sat_f_local['Response'], categories=Response_unique_loc, ordered=True)\n",
    "converttojson(surv_sat_f_local, 'lastyearsurvey_data-localarea')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
